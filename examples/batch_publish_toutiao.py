#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä»Šæ—¥å¤´æ¡æ‰¹é‡æ–‡ç« å‘å¸ƒè„šæœ¬
æ”¯æŒæŒ‡å®šç›®å½•ï¼Œæ‰¹é‡å‘å¸ƒè¯¥ç›®å½•ä¸‹æ‰€æœ‰çš„mdæ–‡ä»¶
"""

import asyncio
import os
import sys
import glob
import time
from datetime import datetime
from playwright.async_api import async_playwright

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from uploader.toutiao_uploader.main import TouTiaoArticle, toutiao_setup

def parse_markdown_file(file_path):
    """è§£æmarkdownæ–‡ä»¶ï¼Œæå–æ ‡é¢˜ã€å†…å®¹å’Œæ ‡ç­¾"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.strip().split('\n')
        
        # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œå¦‚æœæ˜¯#å¼€å¤´ï¼Œæˆ–è€…ä½¿ç”¨æ–‡ä»¶åï¼‰
        title = ""
        content_start_idx = 0
        
        if lines and lines[0].startswith('#'):
            title = lines[0].lstrip('#').strip()
            content_start_idx = 1
        else:
            # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºæ ‡é¢˜ï¼ˆå»æ‰.mdåç¼€ï¼‰
            title = os.path.splitext(os.path.basename(file_path))[0]
            title = title.replace('-', ' ').replace('_', ' ').title()
        
        # æå–å†…å®¹ï¼ˆå»æ‰æ ‡é¢˜è¡Œï¼‰
        article_content = '\n'.join(lines[content_start_idx:]).strip()
        
        # ç®€å•çš„æ ‡ç­¾æå–ï¼ˆåŸºäºæ–‡ä»¶åå’Œå†…å®¹å…³é”®è¯ï¼‰
        tags = extract_tags_from_content(title, article_content, file_path)
        
        return title, article_content, tags
        
    except Exception as e:
        print(f"âŒ è§£ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return None, None, None

def extract_tags_from_content(title, content, file_path):
    """ä»æ ‡é¢˜ã€å†…å®¹å’Œæ–‡ä»¶åä¸­æå–æ ‡ç­¾"""
    tags = []
    
    # åŸºäºæ–‡ä»¶åçš„æ ‡ç­¾æ˜ å°„
    filename = os.path.basename(file_path).lower()
    
    tag_mapping = {
        'ai': ['äººå·¥æ™ºèƒ½', 'AIæŠ€æœ¯', 'æœºå™¨å­¦ä¹ '],
        'medical': ['åŒ»ç–—å¥åº·', 'åŒ»ç–—ç§‘æŠ€', 'å¥åº·ç®¡ç†'],
        'blockchain': ['åŒºå—é“¾', 'æ•°å­—è´§å¸', 'å»ä¸­å¿ƒåŒ–'],
        'supply': ['ä¾›åº”é“¾', 'ç‰©æµç®¡ç†', 'å•†ä¸šæ¨¡å¼'],
        '5g': ['5GæŠ€æœ¯', 'é€šä¿¡æŠ€æœ¯', 'ç½‘ç»œæŠ€æœ¯'],
        'technology': ['ç§‘æŠ€å‘å±•', 'æŠ€æœ¯åˆ›æ–°', 'æ•°å­—åŒ–'],
        'microservice': ['å¾®æœåŠ¡', 'æ¶æ„è®¾è®¡', 'è½¯ä»¶å¼€å‘'],
        'redis': ['Redis', 'æ•°æ®åº“', 'ç¼“å­˜æŠ€æœ¯'],
        'thread': ['å¤šçº¿ç¨‹', 'å¹¶å‘ç¼–ç¨‹', 'æ€§èƒ½ä¼˜åŒ–'],
        'model': ['æŠ€æœ¯æ¨¡å‹', 'ç³»ç»Ÿæ¶æ„', 'è®¾è®¡æ¨¡å¼']
    }
    
    # æ ¹æ®æ–‡ä»¶ååŒ¹é…æ ‡ç­¾
    for keyword, related_tags in tag_mapping.items():
        if keyword in filename:
            tags.extend(related_tags[:2])  # æ¯ä¸ªå…³é”®è¯æœ€å¤šå–2ä¸ªæ ‡ç­¾
    
    # å†…å®¹å…³é”®è¯æ ‡ç­¾
    content_lower = content.lower()
    content_keywords = {
        'äººå·¥æ™ºèƒ½': ['artificial intelligence', 'ai', 'æœºå™¨å­¦ä¹ ', 'machine learning'],
        'åŒºå—é“¾': ['blockchain', 'æ¯”ç‰¹å¸', 'bitcoin', 'åŠ å¯†è´§å¸'],
        '5G': ['5g', 'ç¬¬äº”ä»£', 'é€šä¿¡æŠ€æœ¯'],
        'åŒ»ç–—': ['medical', 'å¥åº·', 'health', 'åŒ»é™¢', 'è¯Šæ–­'],
        'æŠ€æœ¯': ['technology', 'ç§‘æŠ€', 'åˆ›æ–°', 'innovation'],
        'å¼€å‘': ['development', 'ç¼–ç¨‹', 'programming', 'ä»£ç '],
        'æ•°æ®': ['data', 'æ•°æ®åº“', 'database', 'å¤§æ•°æ®']
    }
    
    for tag, keywords in content_keywords.items():
        if any(keyword in content_lower for keyword in keywords):
            if tag not in tags:
                tags.append(tag)
    
    # ç¡®ä¿è‡³å°‘æœ‰ä¸€äº›é€šç”¨æ ‡ç­¾
    if not tags:
        tags = ['æŠ€æœ¯åˆ†äº«', 'ç§‘æŠ€å‘å±•', 'åˆ›æ–°æ€ç»´']
    
    # é™åˆ¶æ ‡ç­¾æ•°é‡ï¼ˆä»Šæ—¥å¤´æ¡å»ºè®®3-6ä¸ªæ ‡ç­¾ï¼‰
    return tags[:6]

def get_markdown_files(directory):
    """è·å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰markdownæ–‡ä»¶"""
    if not os.path.exists(directory):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
        return []
    
    # æ”¯æŒå¤šç§markdownæ–‡ä»¶æ‰©å±•å
    patterns = [
        os.path.join(directory, "*.md"),
        os.path.join(directory, "*.markdown"),
        os.path.join(directory, "*.mdown")
    ]
    
    md_files = []
    for pattern in patterns:
        md_files.extend(glob.glob(pattern))
    
    # æ’åºç¡®ä¿å‘å¸ƒé¡ºåºä¸€è‡´
    md_files.sort()
    
    return md_files

async def publish_single_article(file_path, account_file, delay_seconds=0):
    """å‘å¸ƒå•ä¸ªæ–‡ç« """
    print(f"\n{'='*60}")
    print(f"ğŸ“„ æ­£åœ¨å¤„ç†æ–‡ä»¶: {os.path.basename(file_path)}")
    print(f"{'='*60}")
    
    # è§£æmarkdownæ–‡ä»¶
    title, content, tags = parse_markdown_file(file_path)
    
    if not title or not content:
        print(f"âŒ æ–‡ä»¶è§£æå¤±è´¥ï¼Œè·³è¿‡: {file_path}")
        return False
    
    print(f"ğŸ“ æ ‡é¢˜: {title}")
    print(f"ğŸ·ï¸  æ ‡ç­¾: {tags}")
    print(f"ğŸ“Š å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    print(f"â° å»¶è¿Ÿ: {delay_seconds} ç§’")
    
    # å¦‚æœæœ‰å»¶è¿Ÿï¼Œå…ˆç­‰å¾…
    if delay_seconds > 0:
        print(f"â³ ç­‰å¾… {delay_seconds} ç§’åå¼€å§‹å‘å¸ƒ...")
        await asyncio.sleep(delay_seconds)
    
    try:
        # åˆ›å»ºæ–‡ç« å‘å¸ƒå¯¹è±¡
        article = TouTiaoArticle(
            title=title,
            content=content,
            tags=tags,
            publish_date=0,  # ç«‹å³å‘å¸ƒ
            account_file=account_file,
            cover_path=None  # è‡ªåŠ¨ç”Ÿæˆå°é¢
        )
        
        print("ğŸ¯ å¼€å§‹å‘å¸ƒæ–‡ç« ...")
        
        # å‘å¸ƒæ–‡ç« 
        async with async_playwright() as playwright:
            await article.upload(playwright)
        
        print(f"âœ… æ–‡ç« å‘å¸ƒå®Œæˆ: {title}")
        return True
        
    except Exception as e:
        print(f"âŒ æ–‡ç« å‘å¸ƒå¤±è´¥: {e}")
        return False

async def batch_publish_articles(directory, account_file, delay_between_posts=60):
    """æ‰¹é‡å‘å¸ƒæ–‡ç« """
    print("ğŸš€ ä»Šæ—¥å¤´æ¡æ‰¹é‡æ–‡ç« å‘å¸ƒå·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    print("ğŸ” æ£€æŸ¥ç™»å½•çŠ¶æ€...")
    if not await toutiao_setup(account_file):
        print("âŒ ç™»å½•çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆç™»å½•")
        print("è¿è¡Œä»¥ä¸‹å‘½ä»¤é‡æ–°ç™»å½•:")
        print("python examples/login_toutiao.py")
        return
    
    print("âœ… ç™»å½•çŠ¶æ€æ­£å¸¸")
    
    # è·å–æ‰€æœ‰markdownæ–‡ä»¶
    md_files = get_markdown_files(directory)
    
    if not md_files:
        print(f"âŒ åœ¨ç›®å½• {directory} ä¸­æœªæ‰¾åˆ°ä»»ä½•markdownæ–‡ä»¶")
        return
    
    print(f"\nğŸ“ æ‰¾åˆ° {len(md_files)} ä¸ªmarkdownæ–‡ä»¶:")
    for i, file_path in enumerate(md_files, 1):
        print(f"  {i}. {os.path.basename(file_path)}")
    
    # ç¡®è®¤å‘å¸ƒ
    print(f"\nâš ï¸  å³å°†æ‰¹é‡å‘å¸ƒ {len(md_files)} ç¯‡æ–‡ç« ")
    print(f"ğŸ“… å‘å¸ƒé—´éš”: {delay_between_posts} ç§’")
    print(f"â±ï¸  é¢„è®¡æ€»æ—¶é—´: {len(md_files) * delay_between_posts // 60} åˆ†é’Ÿ")
    
    confirm = input("\nç¡®è®¤å¼€å§‹æ‰¹é‡å‘å¸ƒå—ï¼Ÿ(y/N): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("âŒ ç”¨æˆ·å–æ¶ˆå‘å¸ƒ")
        return
    
    # å¼€å§‹æ‰¹é‡å‘å¸ƒ
    print(f"\nğŸ¯ å¼€å§‹æ‰¹é‡å‘å¸ƒ {len(md_files)} ç¯‡æ–‡ç« ...")
    
    success_count = 0
    failed_count = 0
    
    for i, file_path in enumerate(md_files):
        print(f"\nğŸ“Š è¿›åº¦: {i+1}/{len(md_files)}")
        
        # ç¬¬ä¸€ç¯‡æ–‡ç« ä¸å»¶è¿Ÿï¼Œåç»­æ–‡ç« æœ‰å»¶è¿Ÿ
        delay = 0 if i == 0 else delay_between_posts
        
        success = await publish_single_article(file_path, account_file, delay)
        
        if success:
            success_count += 1
        else:
            failed_count += 1
        
        # æ˜¾ç¤ºå½“å‰ç»Ÿè®¡
        print(f"ğŸ“ˆ å½“å‰ç»Ÿè®¡: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*60}")
    print("ğŸ“Š æ‰¹é‡å‘å¸ƒå®Œæˆç»Ÿè®¡:")
    print(f"âœ… æˆåŠŸå‘å¸ƒ: {success_count} ç¯‡")
    print(f"âŒ å‘å¸ƒå¤±è´¥: {failed_count} ç¯‡")
    print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {len(md_files)} ç¯‡")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {success_count/len(md_files)*100:.1f}%")
    print(f"{'='*60}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä»Šæ—¥å¤´æ¡æ‰¹é‡æ–‡ç« å‘å¸ƒå·¥å…·')
    parser.add_argument('directory', help='åŒ…å«markdownæ–‡ä»¶çš„ç›®å½•è·¯å¾„')
    parser.add_argument('--delay', type=int, default=60, help='æ–‡ç« å‘å¸ƒé—´éš”æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’')
    parser.add_argument('--account', default='cookies/toutiao_uploader/account.json', help='è´¦å·cookieæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ç›®å½•
    if not os.path.exists(args.directory):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.directory}")
        return
    
    # æ£€æŸ¥è´¦å·æ–‡ä»¶
    if not os.path.exists(args.account):
        print(f"âŒ è´¦å·æ–‡ä»¶ä¸å­˜åœ¨: {args.account}")
        print("è¯·å…ˆè¿è¡Œç™»å½•è„šæœ¬: python examples/login_toutiao.py")
        return
    
    print(f"ğŸ“ ç›®æ ‡ç›®å½•: {os.path.abspath(args.directory)}")
    print(f"â° å‘å¸ƒé—´éš”: {args.delay} ç§’")
    print(f"ğŸ”‘ è´¦å·æ–‡ä»¶: {args.account}")
    
    # è¿è¡Œæ‰¹é‡å‘å¸ƒ
    asyncio.run(batch_publish_articles(args.directory, args.account, args.delay))

if __name__ == "__main__":
    main() 