#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ–‡ç« é“¾æ¥è½¬å‘åˆ°ä»Šæ—¥å¤´æ¡å·¥å…· v2.0
æ”¯æŒä»å„ç§ç½‘ç«™æŠ“å–æ–‡ç« å†…å®¹å¹¶è½¬å‘åˆ°ä»Šæ—¥å¤´æ¡
ä¼˜åŒ–æ’ç‰ˆï¼Œæå‡é˜…è¯»ä½“éªŒ
"""

import asyncio
import os
import sys
import re
import time
import hashlib
import textwrap
from datetime import datetime
from urllib.parse import urlparse
from playwright.async_api import async_playwright
import requests
from bs4 import BeautifulSoup, NavigableString, Tag
import markdown

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from uploader.toutiao_uploader.main_final import TouTiaoArticle, toutiao_setup

class WechatSyncStyleFormatter:
    """ä¼˜åŒ–ç‰ˆæ ¼å¼åŒ–å™¨ - è§£å†³ç©ºè¡Œè¿‡å¤šã€ä»£ç å—æ˜¾ç¤ºå’Œmarkdownæ¸²æŸ“é—®é¢˜"""
    
    def __init__(self):
        self.code_languages = {
            'javascript': 'JavaScript', 'js': 'JavaScript',
            'typescript': 'TypeScript', 'ts': 'TypeScript', 
            'python': 'Python', 'py': 'Python',
            'java': 'Java', 'cpp': 'C++', 'c': 'C',
            'html': 'HTML', 'css': 'CSS', 'scss': 'SCSS',
            'shell': 'Shell', 'bash': 'Bash', 'sql': 'SQL',
            'json': 'JSON', 'xml': 'XML', 'yaml': 'YAML'
        }
    
    def html_to_text(self, html_content):
        """å°†HTMLè½¬æ¢ä¸ºæ¸…æ™°çš„æ–‡æœ¬æ ¼å¼ - ä¼˜åŒ–ç‰ˆ"""
        if not html_content:
            return ""
        
        # ä½¿ç”¨BeautifulSoupè§£æ
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ 
        for tag in soup(['script', 'style', 'meta', 'link', 'noscript', 'nav', 'header', 'footer']):
            tag.decompose()
        
        # å¤„ç†ç‰¹æ®Šå…ƒç´ 
        self._preprocess_elements(soup)
        
        # è½¬æ¢ä¸ºæ–‡æœ¬
        result = self._element_to_text(soup)
        
        # åå¤„ç† - ä¼˜åŒ–æ ¼å¼
        return self._postprocess_text(result)
    
    def _preprocess_elements(self, soup):
        """é¢„å¤„ç†HTMLå…ƒç´ """
        # å¤„ç†ä»£ç å—
        for pre in soup.find_all('pre'):
            code = pre.find('code')
            if code:
                language = self._detect_language(code)
                code_text = code.get_text()
                # åˆ›å»ºç‰¹æ®Šæ ‡è®°
                marker = soup.new_tag('div')
                marker['data-type'] = 'codeblock'
                marker['data-language'] = language
                marker.string = code_text
                pre.replace_with(marker)
        
        # å¤„ç†å†…è”ä»£ç 
        for code in soup.find_all('code'):
            if code.parent.name != 'pre':
                code_text = code.get_text()
                marker = soup.new_tag('span')
                marker['data-type'] = 'inline-code'
                marker.string = code_text
                code.replace_with(marker)
        
        # å¤„ç†é“¾æ¥
        for a in soup.find_all('a'):
            href = a.get('href', '')
            text = a.get_text().strip()
            if text and href:
                marker = soup.new_tag('span')
                marker['data-type'] = 'link'
                marker['data-href'] = href
                marker.string = text
                a.replace_with(marker)
    
    def _detect_language(self, code_elem):
        """æ£€æµ‹ä»£ç è¯­è¨€"""
        classes = code_elem.get('class', [])
        if isinstance(classes, list):
            for cls in classes:
                if cls.startswith('language-'):
                    lang = cls.replace('language-', '')
                    return self.code_languages.get(lang, lang.title())
                elif cls.startswith('lang-'):
                    lang = cls.replace('lang-', '')
                    return self.code_languages.get(lang, lang.title())
        
        # å°è¯•ä»çˆ¶å…ƒç´ è·å–è¯­è¨€ä¿¡æ¯
        parent = code_elem.parent
        if parent and parent.get('class'):
            for cls in parent.get('class', []):
                if cls.startswith('language-'):
                    lang = cls.replace('language-', '')
                    return self.code_languages.get(lang, lang.title())
        
        return ''
    
    def _element_to_text(self, element):
        """å°†å…ƒç´ è½¬æ¢ä¸ºæ–‡æœ¬ - ä¼˜åŒ–ç‰ˆ"""
        if isinstance(element, NavigableString):
            return str(element).strip()
        
        if not hasattr(element, 'name'):
            return ""
        
        tag = element.name.lower()
        
        # å¤„ç†ç‰¹æ®Šæ•°æ®ç±»å‹
        if tag == 'div' and element.get('data-type') == 'codeblock':
            language = element.get('data-language', '')
            code_text = element.get_text()
            return self._format_code_block(code_text, language)
        
        elif tag == 'span' and element.get('data-type') == 'inline-code':
            return f"`{element.get_text()}`"
        
        elif tag == 'span' and element.get('data-type') == 'link':
            text = element.get_text()
            href = element.get('data-href', '')
            return f"[{text}]({href})"
        
        # å¤„ç†å­å…ƒç´ 
        children_text = []
        for child in element.children:
            child_text = self._element_to_text(child)
            if child_text:
                children_text.append(child_text)
        
        text = ' '.join(children_text) if children_text else element.get_text().strip()
        
        # æ ¹æ®æ ‡ç­¾æ ¼å¼åŒ– - ä¼˜åŒ–ç‰ˆ
        if tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            level = int(tag[1])
            return self._format_heading(text, level)
        
        elif tag == 'p':
            return text if text else ""  # ç§»é™¤æ®µè½æ ‡ç­¾çš„é¢å¤–æ¢è¡Œ
        
        elif tag in ['strong', 'b']:
            return f"**{text}**" if text else ""
        
        elif tag in ['em', 'i']:
            return f"*{text}*" if text else ""
        
        elif tag in ['ul', 'ol']:
            return self._format_list(element, tag)
        
        elif tag == 'li':
            return text
        
        elif tag == 'blockquote':
            return self._format_quote(text)
        
        elif tag == 'br':
            return "\n"
        
        elif tag == 'hr':
            return "\n---\n"
        
        elif tag in ['div', 'section', 'article']:
            return text if text else ""
        
        elif tag == 'table':
            return self._format_table(element)
        
        else:
            return text
    
    def _format_heading(self, text, level):
        """æ ¼å¼åŒ–æ ‡é¢˜ - ä¼˜åŒ–ç‰ˆ"""
        if not text:
            return ""
        
        text = text.strip()
        
        if level == 1:
            return f"\n# {text}\n"
        elif level == 2:
            return f"\n## {text}\n"
        elif level == 3:
            return f"\n### {text}\n"
        elif level == 4:
            return f"\n#### {text}\n"
        elif level == 5:
            return f"\n##### {text}\n"
        else:
            return f"\n###### {text}\n"
    
    def _format_code_block(self, code_text, language=''):
        """æ ¼å¼åŒ–ä»£ç å— - ä¼˜åŒ–ç‰ˆ"""
        if not code_text:
            return ""
        
        code_text = code_text.strip()
        
        if language:
            lang_display = self.code_languages.get(language.lower(), language)
            return f"\n```{language.lower()}\n{code_text}\n```\n"
        else:
            return f"\n```\n{code_text}\n```\n"
    
    def _format_list(self, element, list_type):
        """æ ¼å¼åŒ–åˆ—è¡¨ - ä¼˜åŒ–ç‰ˆ"""
        items = []
        
        for i, li in enumerate(element.find_all('li', recursive=False), 1):
            li_text = self._element_to_text(li)
            if li_text:
                if list_type == 'ol':
                    items.append(f"{i}. {li_text}")
                else:
                    items.append(f"- {li_text}")
        
        if items:
            return f"\n" + "\n".join(items) + "\n"
        return ""
    
    def _format_quote(self, text):
        """æ ¼å¼åŒ–å¼•ç”¨ - ä¼˜åŒ–ç‰ˆ"""
        if not text:
            return ""
        
        text = text.strip()
        lines = text.split('\n')
        quoted_lines = [f"> {line.strip()}" for line in lines if line.strip()]
        
        if quoted_lines:
            return f"\n" + "\n".join(quoted_lines) + "\n"
        return ""
    
    def _format_table(self, table_element):
        """æ ¼å¼åŒ–è¡¨æ ¼ - ä¼˜åŒ–ç‰ˆ"""
        if not table_element:
            return ""
        
        table_text = table_element.get_text().strip()
        return f"\n{table_text}\n" if table_text else ""
    
    def _postprocess_text(self, text):
        """åå¤„ç†æ–‡æœ¬ - ä¼˜åŒ–ç‰ˆï¼Œè§£å†³ç©ºè¡Œè¿‡å¤šé—®é¢˜"""
        if not text:
            return ""
        
        # ç»Ÿä¸€æ¢è¡Œç¬¦
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        
        # å…ˆåšåŸºç¡€çš„ç©ºè¡Œæ¸…ç†
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        
        # å¤„ç†æ®µè½å†…å®¹ï¼Œæ™ºèƒ½æ·»åŠ æ¢è¡Œ
        lines = text.split('\n')
        processed_lines = []
        
        i = 0
        while i < len(lines):
            line = lines[i]
            processed_lines.append(line)
            
            # å¦‚æœæ˜¯æ ‡é¢˜ï¼Œç¡®ä¿åé¢æœ‰ç©ºè¡Œ
            if re.match(r'^#{1,6}\s', line):
                if i < len(lines) - 1 and lines[i + 1].strip():
                    processed_lines.append('')
            
            # å¦‚æœæ˜¯ä»£ç å—å¼€å§‹æ ‡è®°
            elif line.strip().startswith('```'):
                # æ‰¾åˆ°ä»£ç å—ç»“æŸæ ‡è®°
                j = i + 1
                while j < len(lines) and not lines[j].strip().startswith('```'):
                    j += 1
                
                # å¤åˆ¶ä»£ç å—å†…å®¹
                for k in range(i + 1, j + 1):
                    if k < len(lines):
                        processed_lines.append(lines[k])
                
                # ç¡®ä¿ä»£ç å—åæœ‰ç©ºè¡Œ
                if j < len(lines) - 1 and lines[j + 1].strip():
                    processed_lines.append('')
                
                i = j  # è·³è¿‡å·²å¤„ç†çš„ä»£ç å—
            
            # å¦‚æœæ˜¯åˆ—è¡¨é¡¹ï¼Œä¸æ·»åŠ é¢å¤–ç©ºè¡Œ
            elif re.match(r'^[-*+]\s', line.strip()) or re.match(r'^\d+\.\s', line.strip()):
                pass  # åˆ—è¡¨é¡¹ä¹‹é—´ä¸æ·»åŠ ç©ºè¡Œ
            
            # å¦‚æœæ˜¯å¼•ç”¨ï¼Œä¸æ·»åŠ é¢å¤–ç©ºè¡Œ
            elif line.strip().startswith('>'):
                pass  # å¼•ç”¨è¡Œä¹‹é—´ä¸æ·»åŠ ç©ºè¡Œ
            
            # æ™®é€šæ–‡æœ¬è¡Œçš„å¤„ç†
            elif line.strip():
                # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦ä¹Ÿæ˜¯æ™®é€šæ–‡æœ¬ä¸”å¤Ÿé•¿
                if (i < len(lines) - 1 and 
                    lines[i + 1].strip() and
                    len(line.strip()) > 50 and  # å½“å‰è¡Œè¶³å¤Ÿé•¿
                    len(lines[i + 1].strip()) > 50 and  # ä¸‹ä¸€è¡Œä¹Ÿè¶³å¤Ÿé•¿
                    not lines[i + 1].startswith(('#', '>', '-', '*', '+', '```', '|')) and
                    not line.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', 'ï¼š', 'ï¼Œ'))):  # ä¸æ˜¯å¥å­ç»“å°¾
                    processed_lines.append('')  # æ·»åŠ ç©ºè¡Œåˆ†éš”æ®µè½
            
            i += 1
        
        result = '\n'.join(processed_lines)
        
        # æœ€ç»ˆæ¸…ç†
        # æ¸…ç†æ ‡é¢˜å‰åçš„å¤šä½™ç©ºè¡Œ
        result = re.sub(r'\n+(#{1,6}\s)', r'\n\n\1', result)
        result = re.sub(r'(#{1,6}\s[^\n]*)\n+', r'\1\n\n', result)
        
        # æ¸…ç†ä»£ç å—å‰åçš„å¤šä½™ç©ºè¡Œ
        result = re.sub(r'\n+(```)', r'\n\n\1', result)
        result = re.sub(r'(```[^\n]*\n[\s\S]*?\n```)\n+', r'\1\n\n', result)
        
        # ç¡®ä¿åˆ—è¡¨å‰åæœ‰é€‚å½“çš„ç©ºè¡Œ
        result = re.sub(r'\n+([-*+]\s)', r'\n\n\1', result)
        result = re.sub(r'((?:^[-*+]\s[^\n]*\n)+)\n*', r'\1\n', result, flags=re.MULTILINE)
        
        # ç¡®ä¿å¼•ç”¨å‰åæœ‰é€‚å½“çš„ç©ºè¡Œ
        result = re.sub(r'\n+(>\s)', r'\n\n\1', result)
        result = re.sub(r'((?:^>\s[^\n]*\n)+)\n*', r'\1\n', result, flags=re.MULTILINE)
        
        # æœ€ç»ˆæ¸…ç†ï¼šç¡®ä¿æ²¡æœ‰è¶…è¿‡ä¸¤ä¸ªè¿ç»­çš„ç©ºè¡Œ
        result = re.sub(r'\n{3,}', '\n\n', result)
        
        # æ¸…ç†å¼€å¤´å’Œç»“å°¾çš„ç©ºè¡Œ
        result = result.strip()
        
        return result
    
    def markdown_to_text(self, markdown_content):
        """å°†Markdownè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼ - ä¼˜åŒ–ç‰ˆ"""
        if not markdown_content:
            return ""
        
        # å…ˆè½¬æ¢ä¸ºHTMLï¼Œå†è½¬æ¢ä¸ºæ–‡æœ¬
        try:
            md = markdown.Markdown(extensions=[
                'markdown.extensions.extra',
                'markdown.extensions.codehilite',
                'markdown.extensions.tables',
                'markdown.extensions.toc'
            ])
            html = md.convert(markdown_content)
            return self.html_to_text(html)
        except Exception as e:
            print(f"âš ï¸ Markdownè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–è½¬æ¢: {e}")
            return self._simple_markdown_to_text(markdown_content)
    
    def _simple_markdown_to_text(self, text):
        """ç®€åŒ–çš„Markdownåˆ°æ–‡æœ¬è½¬æ¢ - ä¼˜åŒ–ç‰ˆ"""
        if not text:
            return ""
        
        # å¤„ç†æ ‡é¢˜
        text = re.sub(r'^#{1}\s+(.+)$', r'\n# \1\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{2}\s+(.+)$', r'\n## \1\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{3}\s+(.+)$', r'\n### \1\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{4}\s+(.+)$', r'\n#### \1\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{5,6}\s+(.+)$', r'\n##### \1\n', text, flags=re.MULTILINE)
        
        # å¤„ç†ä»£ç å—
        def replace_code_block(match):
            language = match.group(1) if match.group(1) else ''
            code = match.group(2)
            return self._format_code_block(code, language)
        
        text = re.sub(r'```(\w*)\n(.*?)\n```', replace_code_block, text, flags=re.DOTALL)
        
        # å¤„ç†å†…è”ä»£ç 
        text = re.sub(r'`([^`]+)`', r'`\1`', text)
        
        # å¤„ç†ç²—ä½“å’Œæ–œä½“
        text = re.sub(r'\*\*([^*]+)\*\*', r'**\1**', text)
        text = re.sub(r'\*([^*]+)\*', r'*\1*', text)
        
        # å¤„ç†å¼•ç”¨
        text = re.sub(r'^>\s*(.+)$', r'> \1', text, flags=re.MULTILINE)
        
        # å¤„ç†åˆ—è¡¨
        text = re.sub(r'^[-*+]\s+(.+)$', r'- \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\d+\.\s+(.+)$', r'1. \1', text, flags=re.MULTILINE)
        
        # å¤„ç†é“¾æ¥
        text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'[\1](\2)', text)
        
        # å¤„ç†åˆ†éš”çº¿
        text = re.sub(r'^---+$', '---', text, flags=re.MULTILINE)
        
        # åå¤„ç†
        return self._postprocess_text(text)

class EnhancedArticleForwarder:
    """å¢å¼ºç‰ˆæ–‡ç« è½¬å‘å·¥å…·"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        self.site_configs = {
            'juejin.cn': self._extract_juejin,
            'cnblogs.com': self._extract_cnblogs,
            'csdn.net': self._extract_csdn,
            'jianshu.com': self._extract_jianshu,
            'zhihu.com': self._extract_zhihu,
            'segmentfault.com': self._extract_segmentfault,
            'oschina.net': self._extract_oschina,
        }
        
        # åˆå§‹åŒ–æ ¼å¼åŒ–å™¨
        self.formatter = WechatSyncStyleFormatter()
        
        # å†…å®¹ç¾åŒ–é…ç½®
        self.content_enhancers = {
            'emoji_mapping': {
                'å‰è¨€': 'ğŸ“', 'ä»‹ç»': 'ğŸ“–', 'æ¦‚è¿°': 'ğŸ”',
                'å®‰è£…': 'âš™ï¸', 'é…ç½®': 'ğŸ”§', 'ä½¿ç”¨': 'ğŸš€',
                'ç¤ºä¾‹': 'ğŸ’¡', 'ä¾‹å­': 'ğŸ’¡', 'ä»£ç ': 'ğŸ’»',
                'æ€»ç»“': 'ğŸ“‹', 'ç»“è®º': 'ğŸ¯', 'å°ç»“': 'ğŸ“',
                'æ³¨æ„': 'âš ï¸', 'è­¦å‘Š': 'ğŸš¨', 'æç¤º': 'ğŸ’¡',
                'ä¼˜ç‚¹': 'âœ…', 'ç¼ºç‚¹': 'âŒ', 'ç‰¹ç‚¹': 'ğŸ¯',
                'æ­¥éª¤': 'ğŸ“', 'æ–¹æ³•': 'ğŸ”§', 'æŠ€å·§': 'ğŸ’¡',
                'é—®é¢˜': 'â“', 'è§£å†³': 'âœ…', 'é”™è¯¯': 'âŒ',
                'æ€§èƒ½': 'âš¡', 'å®‰å…¨': 'ğŸ”’', 'æµ‹è¯•': 'ğŸ§ª'
            }
        }
    
    def _markdown_to_html(self, markdown_content):
        """å°†Markdownå†…å®¹è½¬æ¢ä¸ºHTML"""
        if not markdown_content:
            return ""
        
        try:
            # é‡ç½®è½¬æ¢å™¨çŠ¶æ€
            self.markdown_converter.reset()
            
            # è½¬æ¢Markdownä¸ºHTML
            html_content = self.markdown_converter.convert(markdown_content)
            
            # ä¼˜åŒ–HTMLæ ¼å¼
            html_content = self._optimize_html_format(html_content)
            
            return html_content
            
        except Exception as e:
            print(f"âš ï¸ Markdownè½¬æ¢å¤±è´¥: {e}")
            return markdown_content
    
    def _optimize_html_format(self, html_content):
        """ä¼˜åŒ–HTMLæ ¼å¼"""
        if not html_content:
            return ""
        
        # ä¸ºæ®µè½æ·»åŠ é—´è·
        html_content = re.sub(r'<p>', '<p style="margin: 16px 0; line-height: 1.6;">', html_content)
        
        # ä¸ºæ ‡é¢˜æ·»åŠ æ ·å¼
        html_content = re.sub(r'<h1>', '<h1 style="font-size: 24px; font-weight: bold; margin: 24px 0 16px 0; color: #333;">', html_content)
        html_content = re.sub(r'<h2>', '<h2 style="font-size: 22px; font-weight: bold; margin: 20px 0 14px 0; color: #333; border-bottom: 2px solid #eee; padding-bottom: 8px;">', html_content)
        html_content = re.sub(r'<h3>', '<h3 style="font-size: 20px; font-weight: bold; margin: 18px 0 12px 0; color: #333;">', html_content)
        html_content = re.sub(r'<h4>', '<h4 style="font-size: 18px; font-weight: bold; margin: 16px 0 10px 0; color: #333;">', html_content)
        html_content = re.sub(r'<h5>', '<h5 style="font-size: 16px; font-weight: bold; margin: 14px 0 8px 0; color: #333;">', html_content)
        html_content = re.sub(r'<h6>', '<h6 style="font-size: 14px; font-weight: bold; margin: 12px 0 6px 0; color: #333;">', html_content)
        
        # ä¸ºé“¾æ¥æ·»åŠ æ ·å¼
        html_content = re.sub(r'<a ', '<a style="color: #1890ff; text-decoration: none;" ', html_content)
        
        # ä¸ºå¼ºè°ƒæ–‡æœ¬æ·»åŠ æ ·å¼
        html_content = re.sub(r'<strong>', '<strong style="font-weight: bold; color: #333;">', html_content)
        html_content = re.sub(r'<em>', '<em style="font-style: italic; color: #666;">', html_content)
        
        # ä¸ºä»£ç æ·»åŠ æ ·å¼
        html_content = re.sub(
            r'<code>',
            '<code style="background-color: #f6f8fa; color: #d73a49; padding: 2px 4px; border-radius: 3px; font-family: monospace; font-size: 0.9em;">',
            html_content
        )
        
        # ä¸ºä»£ç å—æ·»åŠ æ ·å¼
        html_content = re.sub(
            r'<pre>',
            '<pre style="background-color: #f6f8fa; border: 1px solid #e1e4e8; border-radius: 6px; padding: 16px; overflow-x: auto; margin: 16px 0; font-family: monospace; font-size: 14px; line-height: 1.45;">',
            html_content
        )
        
        # ä¸ºå¼•ç”¨å—æ·»åŠ æ ·å¼
        html_content = re.sub(
            r'<blockquote>',
            '<blockquote style="border-left: 4px solid #dfe2e5; margin: 16px 0; padding: 0 16px; color: #6a737d; background-color: #f8f9fa; border-radius: 0 6px 6px 0;">',
            html_content
        )
        
        # ä¸ºåˆ—è¡¨æ·»åŠ æ ·å¼
        html_content = re.sub(r'<ul>', '<ul style="margin: 16px 0; padding-left: 24px;">', html_content)
        html_content = re.sub(r'<ol>', '<ol style="margin: 16px 0; padding-left: 24px;">', html_content)
        html_content = re.sub(r'<li>', '<li style="margin: 4px 0; line-height: 1.6;">', html_content)
        
        # ä¸ºè¡¨æ ¼æ·»åŠ æ ·å¼
        html_content = re.sub(r'<table>', '<table style="border-collapse: collapse; width: 100%; border: 1px solid #e1e4e8; margin: 16px 0;">', html_content)
        html_content = re.sub(r'<th>', '<th style="background-color: #f6f8fa; border: 1px solid #e1e4e8; padding: 8px 12px; text-align: left; font-weight: bold;">', html_content)
        html_content = re.sub(r'<td>', '<td style="border: 1px solid #e1e4e8; padding: 8px 12px;">', html_content)
        
        return html_content
    
    def _markdown_to_rich_text(self, markdown_content):
        """å°†Markdownå†…å®¹è½¬æ¢ä¸ºå¯Œæ–‡æœ¬æ ¼å¼ï¼ˆä¸æ˜¯HTMLä»£ç ï¼‰"""
        if not markdown_content:
            return ""
        
        try:
            # å…ˆè½¬æ¢ä¸ºHTML
            html_content = self.markdown_converter.convert(markdown_content)
            
            # å°†HTMLè½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼Œä½†ä¿ç•™æ ¼å¼æ•ˆæœ
            rich_text = self._html_to_formatted_text(html_content)
            
            return rich_text
            
        except Exception as e:
            print(f"âš ï¸ å¯Œæ–‡æœ¬è½¬æ¢å¤±è´¥: {e}")
            return self._markdown_to_plain_text(markdown_content)
    
    def _html_to_formatted_text(self, html_content):
        """å°†HTMLè½¬æ¢ä¸ºæ ¼å¼åŒ–çš„çº¯æ–‡æœ¬"""
        if not html_content:
            return ""
        
        # ä½¿ç”¨BeautifulSoupè§£æHTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # é€’å½’å¤„ç†HTMLå…ƒç´ ï¼Œè½¬æ¢ä¸ºæ ¼å¼åŒ–æ–‡æœ¬
        def process_html_element(element, depth=0):
            if isinstance(element, NavigableString):
                return str(element).strip()
            
            if not hasattr(element, 'name'):
                return ""
            
            tag_name = element.name.lower()
            
            # è·å–å­å…ƒç´ å†…å®¹
            children_text = []
            for child in element.children:
                child_text = process_html_element(child, depth + 1)
                if child_text:
                    children_text.append(child_text)
            
            content = ' '.join(children_text) if children_text else element.get_text().strip()
            
            # æ ¹æ®HTMLæ ‡ç­¾è½¬æ¢ä¸ºç›¸åº”çš„æ–‡æœ¬æ ¼å¼
            if tag_name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                level = int(tag_name[1])
                if content:
                    # ä½¿ç”¨ä¸åŒçš„è£…é¥°ç¬¦è¡¨ç¤ºæ ‡é¢˜å±‚çº§
                    if level == 1:
                        return f"\n\n{'=' * 50}\n{content}\n{'=' * 50}\n\n"
                    elif level == 2:
                        return f"\n\n{'-' * 40}\n{content}\n{'-' * 40}\n\n"
                    elif level == 3:
                        return f"\n\nâ–¶ {content}\n{'-' * len(content)}\n\n"
                    else:
                        return f"\n\nâ— {content}\n\n"
            
            elif tag_name == 'p':
                return f"\n\n{content}\n\n"
            
            elif tag_name in ['strong', 'b']:
                return f"ã€{content}ã€‘"  # ä½¿ç”¨ä¸­æ–‡æ‹¬å·è¡¨ç¤ºç²—ä½“
            
            elif tag_name in ['em', 'i']:
                return f"ã€Š{content}ã€‹"  # ä½¿ç”¨ä¹¦åå·è¡¨ç¤ºæ–œä½“
            
            elif tag_name == 'code':
                if content:
                    return f"ã€Œ{content}ã€"  # ä½¿ç”¨ç›´è§’å¼•å·è¡¨ç¤ºä»£ç 
            
            elif tag_name == 'pre':
                if content:
                    return f"\n\nâ”Œâ”€ ä»£ç ç¤ºä¾‹ â”€â”\n{content}\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n"
            
            elif tag_name in ['ul', 'ol']:
                if children_text:
                    return f"\n\n" + "\n".join(children_text) + "\n\n"
            
            elif tag_name == 'li':
                if content:
                    return f"â€¢ {content}"
            
            elif tag_name == 'blockquote':
                if content:
                    lines = content.split('\n')
                    quoted_lines = [f"â”ƒ {line.strip()}" for line in lines if line.strip()]
                    return f"\n\n" + "\n".join(quoted_lines) + "\n\n"
            
            elif tag_name == 'a':
                href = element.get('href', '')
                if text_content and href:
                    return f"{text_content}ï¼ˆ{href}ï¼‰"
                else:
                    return text_content
            
            elif tag_name == 'table':
                return f"\n\nğŸ“Š è¡¨æ ¼æ•°æ®ï¼š\n{content}\n\n"
            
            elif tag_name in ['th', 'td']:
                return f" {content} |"
            
            elif tag_name == 'tr':
                return f"|{content}\n"
            
            elif tag_name == 'hr':
                return f"\n\n{'â”€' * 50}\n\n"
            
            elif tag_name == 'br':
                return "\n"
            
            else:
                return content
        
        # å¤„ç†æ•´ä¸ªHTMLæ–‡æ¡£
        result = process_html_element(soup)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        if result:
            result = re.sub(r'\n{3,}', '\n\n', result)
            result = result.strip()
        
        return result
    
    def _markdown_to_plain_text(self, markdown_content):
        """å°†Markdownè½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        if not markdown_content:
            return ""
        
        # ç®€å•çš„Markdownåˆ°æ–‡æœ¬è½¬æ¢
        text = markdown_content
        
        # å¤„ç†æ ‡é¢˜
        text = re.sub(r'^#{1}\s+(.+)$', r'\n\n=== \1 ===\n\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{2}\s+(.+)$', r'\n\n--- \1 ---\n\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{3,6}\s+(.+)$', r'\n\nâ–¶ \1\n\n', text, flags=re.MULTILINE)
        
        # å¤„ç†ç²—ä½“å’Œæ–œä½“
        text = re.sub(r'\*\*(.+?)\*\*', r'ã€\1ã€‘', text)
        text = re.sub(r'\*(.+?)\*', r'ã€Š\1ã€‹', text)
        
        # å¤„ç†ä»£ç 
        text = re.sub(r'`(.+?)`', r'ã€Œ\1ã€', text)
        text = re.sub(r'```[\w]*\n(.*?)\n```', r'\n\nâ”Œâ”€ ä»£ç ç¤ºä¾‹ â”€â”\n\1\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n', text, flags=re.DOTALL)
        
        # å¤„ç†å¼•ç”¨
        text = re.sub(r'^>\s*(.+)$', r'â”ƒ \1', text, flags=re.MULTILINE)
        
        # å¤„ç†åˆ—è¡¨
        text = re.sub(r'^[-*+]\s+(.+)$', r'- \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\d+\.\s+(.+)$', r'â€¢ \1', text, flags=re.MULTILINE)
        
        # å¤„ç†é“¾æ¥
        text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'\1ï¼ˆ\2ï¼‰', text)
        
        # å¤„ç†åˆ†éš”çº¿
        text = re.sub(r'^---+$', 'â”€' * 50, text, flags=re.MULTILINE)
        
        # æ¸…ç†å¤šä½™ç©ºè¡Œ
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        return text.strip()
    
    def _clean_text(self, text):
        """æ¸…ç†æ–‡æœ¬å†…å®¹"""
        if not text:
            return ""
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)  # å¤šä¸ªæ¢è¡Œå˜ä¸ºä¸¤ä¸ª
        text = re.sub(r'[ \t]+', ' ', text)  # å¤šä¸ªç©ºæ ¼å˜ä¸ºä¸€ä¸ª
        text = re.sub(r'^\s+|\s+$', '', text, flags=re.MULTILINE)  # å»é™¤è¡Œé¦–è¡Œå°¾ç©ºæ ¼
        
        # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'[\u200b\u200c\u200d\ufeff]', '', text)  # é›¶å®½å­—ç¬¦
        text = text.strip()
        
        return text
    
    def _remove_unwanted_elements(self, soup):
        """ç§»é™¤ä¸éœ€è¦çš„HTMLå…ƒç´ """
        # ç§»é™¤scriptã€styleã€navç­‰ä¸éœ€è¦çš„æ ‡ç­¾
        unwanted_tags = [
            'script', 'style', 'nav', 'header', 'footer', 'aside',
            'advertisement', 'ad', 'sidebar', 'menu', 'breadcrumb',
            'iframe', 'embed', 'object'
        ]
        
        for tag_name in unwanted_tags:
            for tag in soup.find_all(tag_name):
                tag.decompose()
        
        # ç§»é™¤å¸¸è§çš„å¹¿å‘Šå’Œæ— å…³å†…å®¹çš„class/id
        unwanted_patterns = [
            r'ad[_-]', r'advertisement', r'sponsor', r'promo', 
            r'sidebar', r'related', r'comment', r'footer', 
            r'header', r'nav', r'breadcrumb', r'pagination', 
            r'share', r'social', r'tracking', r'analytics'
        ]
        
        for pattern in unwanted_patterns:
            for tag in soup.find_all(class_=re.compile(pattern, re.I)):
                tag.decompose()
            for tag in soup.find_all(id=re.compile(pattern, re.I)):
                tag.decompose()
        
        return soup
    
    def _enhance_title_with_emoji(self, title):
        """ä¸ºæ ‡é¢˜æ·»åŠ åˆé€‚çš„emoji"""
        title_lower = title.lower()
        
        for keyword, emoji in self.content_enhancers['emoji_mapping'].items():
            if keyword in title_lower:
                if not title.startswith(emoji):
                    return f"{emoji} {title}"
                break
        
        return title
    
    def _detect_code_language(self, code_elem):
        """æ£€æµ‹ä»£ç è¯­è¨€"""
        # ä»classå±æ€§æ£€æµ‹
        class_attr = code_elem.get('class', [])
        if class_attr:
            for cls in class_attr:
                for lang_key, lang_name in self.content_enhancers['code_languages'].items():
                    if lang_key in cls.lower():
                        return lang_key
        
        # ä»å†…å®¹ç‰¹å¾æ£€æµ‹
        code_text = code_elem.get_text()[:200].lower()
        
        language_patterns = {
            'javascript': [r'function\s*\(', r'const\s+\w+', r'let\s+\w+', r'console\.log'],
            'python': [r'def\s+\w+\(', r'import\s+\w+', r'from\s+\w+\s+import', r'print\('],
            'java': [r'public\s+class', r'public\s+static\s+void', r'System\.out\.println'],
            'css': [r'\.\w+\s*{', r'#\w+\s*{', r'@media', r'flex'],
            'html': [r'<html', r'<div', r'<span', r'<!DOCTYPE'],
            'json': [r'^\s*[{\[]', r'"\w+":', r'},\s*"'],
            'sql': [r'SELECT\s+', r'FROM\s+', r'WHERE\s+', r'INSERT\s+INTO']
        }
        
        for lang, patterns in language_patterns.items():
            if any(re.search(pattern, code_text, re.I) for pattern in patterns):
                return lang
        
        return ''
    
    def _format_code_block(self, code_elem):
        """æ ¼å¼åŒ–ä»£ç å—"""
        code_text = code_elem.get_text()
        
        # æ£€æµ‹è¯­è¨€
        language = self._detect_code_language(code_elem)
        lang_display = self.content_enhancers['code_languages'].get(language, language)
        
        # æ¸…ç†ä»£ç æ–‡æœ¬
        code_text = code_text.strip()
        
        # æ·»åŠ è¯­è¨€æ ‡æ³¨
        if lang_display:
            return f"\n\nğŸ’» **{lang_display} ä»£ç ç¤ºä¾‹ï¼š**\n\n```{language}\n{code_text}\n```\n\n"
        else:
            return f"\n\n```\n{code_text}\n```\n\n"
    
    def _format_list_item(self, li_elem, list_type='ul', index=1):
        """æ ¼å¼åŒ–åˆ—è¡¨é¡¹"""
        text = li_elem.get_text().strip()
        
        if list_type == 'ol':
            prefix = f"{index}."
        else:
            # æ ¹æ®å†…å®¹é€‰æ‹©ä¸åŒçš„å‰ç¼€
            if any(keyword in text.lower() for keyword in ['ä¼˜ç‚¹', 'å¥½å¤„', 'ä¼˜åŠ¿']):
                prefix = "âœ…"
            elif any(keyword in text.lower() for keyword in ['ç¼ºç‚¹', 'é—®é¢˜', 'ä¸è¶³']):
                prefix = "âŒ"
            elif any(keyword in text.lower() for keyword in ['æ³¨æ„', 'è­¦å‘Š', 'å°å¿ƒ']):
                prefix = "âš ï¸"
            elif any(keyword in text.lower() for keyword in ['é‡è¦', 'å…³é”®', 'æ ¸å¿ƒ']):
                prefix = "ğŸ”‘"
            else:
                prefix = "â€¢"
        
        return f"{prefix} {text}"
    
    def _extract_juejin(self, soup, url):
        """æå–æ˜é‡‘æ–‡ç« å†…å®¹"""
        # ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ 
        soup = self._remove_unwanted_elements(soup)
        
        # æå–æ ‡é¢˜
        title_selectors = [
            'h1.article-title',
            '.article-title', 
            'h1',
            '[data-page-title]'
        ]
        
        title = "æœªçŸ¥æ ‡é¢˜"
        for selector in title_selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                title = title_elem.get_text().strip()
                break
        
        # æŸ¥æ‰¾æ–‡ç« å†…å®¹å®¹å™¨
        content_selectors = [
            '.markdown-body',
            '.article-content', 
            '[data-v-md-line]',
            '.content',
            'article',
            '.post-content'
        ]
        
        content_elem = None
        for selector in content_selectors:
            content_elem = soup.select_one(selector)
            if content_elem:
                break
        
        if not content_elem:
            # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šå®¹å™¨ï¼Œå°è¯•æ‰¾ä¸»è¦å†…å®¹åŒºåŸŸ
            main_content = soup.find('main') or soup.find('div', class_=re.compile(r'content|article|post'))
            if main_content:
                content_elem = main_content
        
        content = ""
        if content_elem:
            # ä½¿ç”¨æ–°çš„æ ¼å¼åŒ–å™¨è½¬æ¢HTMLä¸ºæ–‡æœ¬
            content = self.formatter.html_to_text(str(content_elem))
        
        # æå–æ ‡ç­¾
        tags = self._extract_tags_juejin(soup)
        
        return title, content, tags
    
    def _extract_cnblogs(self, soup, url):
        """æå–åšå®¢å›­æ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='postTitle') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', id='cnblogs_post_body') or soup.find('div', class_='postBody')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        tags = ['æŠ€æœ¯åˆ†äº«', 'åšå®¢å›­']
        return title, content, tags
    
    def _extract_csdn(self, soup, url):
        """æå–CSDNæ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='title-article') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', id='content_views') or soup.find('div', class_='markdown_views')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        # æå–CSDNæ ‡ç­¾
        tag_elems = soup.find_all('a', class_='tag-link')
        tags = [tag.get_text().strip() for tag in tag_elems[:5]] if tag_elems else ['æŠ€æœ¯åˆ†äº«', 'CSDN']
        
        return title, content, tags
    
    def _extract_jianshu(self, soup, url):
        """æå–ç®€ä¹¦æ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='title') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', class_='show-content') or soup.find('article')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        tags = ['æŠ€æœ¯åˆ†äº«', 'ç®€ä¹¦']
        return title, content, tags
    
    def _extract_zhihu(self, soup, url):
        """æå–çŸ¥ä¹æ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='Post-Title') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', class_='RichText') or soup.find('div', class_='Post-RichTextContainer')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        # æå–çŸ¥ä¹è¯é¢˜æ ‡ç­¾
        topic_elems = soup.find_all('a', class_='TopicLink')
        tags = [topic.get_text().strip() for topic in topic_elems[:5]] if topic_elems else ['çŸ¥è¯†åˆ†äº«', 'çŸ¥ä¹']
        
        return title, content, tags
    
    def _extract_segmentfault(self, soup, url):
        """æå–SegmentFaultæ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='article__title') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', class_='article__content') or soup.find('div', class_='markdown-body')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        # æå–æ ‡ç­¾
        tag_elems = soup.find_all('a', class_='article-tag')
        tags = [tag.get_text().strip() for tag in tag_elems[:5]] if tag_elems else ['æŠ€æœ¯åˆ†äº«', 'SegmentFault']
        
        return title, content, tags
    
    def _extract_oschina(self, soup, url):
        """æå–å¼€æºä¸­å›½æ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='article-box__title') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', class_='article-detail') or soup.find('div', class_='content')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        tags = ['æŠ€æœ¯åˆ†äº«', 'å¼€æºä¸­å›½']
        return title, content, tags
    
    def _extract_tags_juejin(self, soup):
        """æå–æ˜é‡‘æ–‡ç« æ ‡ç­¾"""
        tag_selectors = [
            '.tag-list .tag',
            '.article-tag',
            '.tag',
            '[data-tag]'
        ]
        
        tags = []
        for selector in tag_selectors:
            tag_elems = soup.select(selector)
            if tag_elems:
                tags = [tag.get_text().strip() for tag in tag_elems[:6] if tag.get_text().strip()]
                break
        
        if not tags:
            tags = ['æŠ€æœ¯åˆ†äº«', 'æ˜é‡‘']
        
        return tags
    
    def _html_to_markdown_enhanced(self, element):
        """å¢å¼ºç‰ˆHTMLåˆ°Markdownè½¬æ¢"""
        if not element:
            return ""
        
        def process_element(elem, depth=0):
            """é€’å½’å¤„ç†HTMLå…ƒç´ """
            if isinstance(elem, NavigableString):
                text = str(elem).strip()
                return text if text else ""
            
            if not isinstance(elem, Tag):
                return ""
            
            tag_name = elem.name.lower()
            
            # è·³è¿‡ä¸éœ€è¦çš„æ ‡ç­¾
            if tag_name in ['script', 'style', 'meta', 'link', 'head']:
                return ""
            
            # è·å–å­å…ƒç´ å†…å®¹
            children_content = []
            for child in elem.children:
                child_result = process_element(child, depth + 1)
                if child_result:
                    children_content.append(child_result)
            
            text_content = ' '.join(children_content) if children_content else elem.get_text().strip()
            
            # æ ¹æ®æ ‡ç­¾ç±»å‹è¿›è¡Œè½¬æ¢
            if tag_name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                level = int(tag_name[1])
                if text_content:
                    # ä¸ºæ ‡é¢˜æ·»åŠ emoji
                    enhanced_title = self._enhance_title_with_emoji(text_content)
                    return f"\n\n{'#' * level} {enhanced_title}\n\n"
            
            elif tag_name == 'p':
                if text_content:
                    return f"\n\n{text_content}\n\n"
            
            elif tag_name in ['strong', 'b']:
                if text_content:
                    return f"**{text_content}**"
            
            elif tag_name in ['em', 'i']:
                if text_content:
                    return f"*{text_content}*"
            
            elif tag_name == 'code' and elem.parent.name != 'pre':
                if text_content:
                    return f"`{text_content}`"
            
            elif tag_name == 'pre':
                # å¤„ç†ä»£ç å—
                code_elem = elem.find('code')
                if code_elem:
                    return self._format_code_block(code_elem)
                else:
                    return f"\n\n```\n{text_content}\n```\n\n"
            
            elif tag_name in ['ul', 'ol']:
                # å¤„ç†åˆ—è¡¨
                list_items = []
                for i, li in enumerate(elem.find_all('li', recursive=False), 1):
                    li_content = process_element(li, depth + 1)
                    if li_content:
                        formatted_item = self._format_list_item(li, tag_name, i)
                        list_items.append(formatted_item)
                
                if list_items:
                    return f"\n\n" + "\n".join(list_items) + "\n\n"
            
            elif tag_name == 'li':
                return text_content
            
            elif tag_name == 'blockquote':
                if text_content:
                    # å¤„ç†å¼•ç”¨å—
                    quoted_lines = text_content.split('\n')
                    quoted_text = '\n'.join(f"> ğŸ’¡ {line.strip()}" for line in quoted_lines if line.strip())
                    return f"\n\n{quoted_text}\n\n"
            
            elif tag_name == 'a':
                href = element.get('href', '')
                if text_content and href:
                    return f"[{text_content}]({href})"
                else:
                    return text_content
            
            elif tag_name == 'img':
                alt = element.get('alt', 'å›¾ç‰‡')
                src = element.get('src', '')
                if src:
                    return f"\n\n![{alt}]({src})\n\n"
            
            elif tag_name in ['table']:
                return f"\n\nğŸ“Š **æ•°æ®è¡¨æ ¼**\n\n{text_content}\n\n"
            
            elif tag_name in ['br']:
                return "\n"
            
            elif tag_name in ['hr']:
                return f"\n\n---\n\n"
            
            elif tag_name in ['div', 'section', 'article']:
                # å¯¹äºå®¹å™¨å…ƒç´ ï¼Œè¿”å›å­å…ƒç´ å†…å®¹
                if children_content:
                    return ' '.join(children_content)
                else:
                    return text_content
            
            else:
                return text_content
        
        # å¤„ç†æ•´ä¸ªå…ƒç´ 
        result = process_element(element)
        
        # æ¸…ç†å’Œæ ¼å¼åŒ–ç»“æœ
        if result:
            result = self._clean_text(result)
            # ç¡®ä¿æ®µè½ä¹‹é—´æœ‰é€‚å½“çš„åˆ†éš”
            result = re.sub(r'\n{3,}', '\n\n', result)
            # æ¸…ç†åˆ—è¡¨æ ¼å¼
            result = re.sub(r'\n+(â€¢|âœ…|âŒ|âš ï¸|ğŸ”‘|\d+\.)\s+', r'\n\1 ', result)
            
        return result
    
    def _extract_generic(self, soup, url):
        """é€šç”¨æ–‡ç« å†…å®¹æå–"""
        soup = self._remove_unwanted_elements(soup)
        
        # å°è¯•å¤šç§æ ‡é¢˜é€‰æ‹©å™¨
        title_selectors = ['h1', '.title', '.article-title', '.post-title', '[data-title]']
        title = "æœªçŸ¥æ ‡é¢˜"
        
        for selector in title_selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                title = title_elem.get_text().strip()
                break
        
        # å°è¯•å¤šç§å†…å®¹é€‰æ‹©å™¨
        content_selectors = [
            'article', '.content', '.article-content', '.post-content',
            '.markdown-body', '.article-body', '.entry-content',
            'main', '.main-content', '.post-body'
        ]
        content = ""
        
        for selector in content_selectors:
            content_elem = soup.select_one(selector)
            if content_elem:
                content = self._html_to_markdown_enhanced(content_elem)
                if len(content) > 100:  # ç¡®ä¿è·å–åˆ°è¶³å¤Ÿçš„å†…å®¹
                    break
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°å†…å®¹ï¼Œå°è¯•æ™ºèƒ½æå–
        if not content or len(content) < 100:
            content = self._smart_content_extraction(soup)
        
        tags = ['æ–‡ç« è½¬å‘', 'æŠ€æœ¯åˆ†äº«']
        return title, content, tags
    
    def _smart_content_extraction(self, soup):
        """æ™ºèƒ½å†…å®¹æå–ç®—æ³•"""
        # æ‰¾åˆ°æ‰€æœ‰å¯èƒ½åŒ…å«å†…å®¹çš„div
        content_divs = soup.find_all('div')
        
        best_content = ""
        max_text_length = 0
        
        for div in content_divs:
            # è·³è¿‡æ˜æ˜¾çš„å¯¼èˆªã€å¹¿å‘Šç­‰åŒºåŸŸ
            div_class = ' '.join(div.get('class', [])).lower()
            div_id = (div.get('id') or '').lower()
            
            skip_patterns = ['nav', 'menu', 'sidebar', 'footer', 'header', 'ad', 'comment']
            if any(pattern in div_class or pattern in div_id for pattern in skip_patterns):
                continue
            
            div_text = div.get_text().strip()
            
            # é€‰æ‹©æ–‡æœ¬æœ€é•¿çš„divä½œä¸ºä¸»è¦å†…å®¹
            if len(div_text) > max_text_length:
                max_text_length = len(div_text)
                best_content = self._html_to_markdown_enhanced(div)
        
        return best_content
    
    async def fetch_article(self, url):
        """è·å–æ–‡ç« å†…å®¹"""
        print(f"ğŸŒ æ­£åœ¨è·å–æ–‡ç« : {url}")
        
        try:
            # å‘é€HTTPè¯·æ±‚
            response = requests.get(url, headers=self.headers, timeout=30)
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None, None, None
            
            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æ ¹æ®ç½‘ç«™ç±»å‹é€‰æ‹©æå–å™¨
            domain = urlparse(url).netloc.lower()
            extractor = None
            
            for site, extract_func in self.site_configs.items():
                if site in domain:
                    extractor = extract_func
                    break
            
            if not extractor:
                extractor = self._extract_generic
            
            title, content, tags = extractor(soup, url)
            
            print(f"âœ… æ–‡ç« è·å–æˆåŠŸ:")
            print(f"ğŸ“ æ ‡é¢˜: {title}")
            print(f"ğŸ“Š å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            print(f"ğŸ·ï¸ æ ‡ç­¾: {tags}")
            
            return title, content, tags
            
        except Exception as e:
            print(f"âŒ è·å–æ–‡ç« å¤±è´¥: {e}")
            return None, None, None
    
    def _enhance_content_format(self, title, content, url, use_rich_text=True):
        """å¢å¼ºå†…å®¹æ ¼å¼ - wechatSyncç®€æ´é£æ ¼"""
        # æ„å»ºåŸºç¡€å†…å®¹ç»“æ„
        enhanced_content = f"# {title}\n\n"
        
        # æ·»åŠ æ¥æºä¿¡æ¯ - ç®€æ´æ ·å¼
        enhanced_content += f"> **åŸæ–‡é“¾æ¥**: {url}\n"
        enhanced_content += f"> **è½¬å‘æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
        enhanced_content += f"> **å†…å®¹ä¼˜åŒ–**: å·²ä¼˜åŒ–æ’ç‰ˆæ ¼å¼ï¼Œæå‡é˜…è¯»ä½“éªŒ\n\n"
        enhanced_content += "---\n\n"
        
        # å¤„ç†ä¸»è¦å†…å®¹
        if content:
            # ä½¿ç”¨ç®€æ´é£æ ¼æ ¼å¼åŒ–å™¨å¤„ç†å†…å®¹
            if use_rich_text:
                print("ğŸ¨ æ­£åœ¨ä½¿ç”¨wechatSyncç®€æ´é£æ ¼æ ¼å¼åŒ–å™¨å¤„ç†å†…å®¹...")
                # å¦‚æœå†…å®¹æ˜¯HTMLï¼Œç›´æ¥è½¬æ¢
                if '<' in content and '>' in content:
                    formatted_content = self.formatter.html_to_text(content)
                else:
                    # å¦‚æœæ˜¯Markdownï¼Œå…ˆè½¬æ¢
                    formatted_content = self.formatter.markdown_to_text(content)
                
                # è°ƒæ•´æ ‡é¢˜å±‚çº§ï¼ˆé¿å…ä¸ä¸»æ ‡é¢˜å†²çªï¼‰
                formatted_content = re.sub(r'^# ', '## ', formatted_content, flags=re.MULTILINE)
                formatted_content = re.sub(r'^## ', '### ', formatted_content, flags=re.MULTILINE)
                
                enhanced_content += formatted_content
            else:
                # ç®€å•æ–‡æœ¬å¤„ç†
                content = self._clean_text(content)
                # åº”ç”¨åŸºæœ¬æ ¼å¼åŒ–
                content = self.formatter._simple_markdown_to_text(content)
                enhanced_content += content
        else:
            enhanced_content += "æš‚æ— å†…å®¹æ‘˜è¦ï¼Œè¯·æŸ¥çœ‹åŸæ–‡é“¾æ¥è·å–å®Œæ•´å†…å®¹ã€‚\n\n"
        
        print(f"âœ… å†…å®¹æ ¼å¼åŒ–å®Œæˆï¼Œæœ€ç»ˆé•¿åº¦: {len(enhanced_content)} å­—ç¬¦")
        print(f"ğŸ“ æ ¼å¼åŒ–ç‰¹æ€§: ç®€æ´æ ‡é¢˜ã€æ¸…æ™°ä»£ç å—ã€é€‚å½“æ®µè½é—´è·")
        return enhanced_content
    
    def _optimize_content_spacing(self, content):
        """ä¼˜åŒ–å†…å®¹é—´è·"""
        if not content:
            return ""
        
        # ç¡®ä¿ä»£ç å—å‰åæœ‰ç©ºè¡Œ
        content = re.sub(r'([^\n])\n(```)', r'\1\n\n\2', content)
        content = re.sub(r'(```[^\n]*\n.*?\n```)\n([^\n])', r'\1\n\n\2', content, flags=re.DOTALL)
        
        # ç¡®ä¿æ ‡é¢˜å‰åæœ‰ç©ºè¡Œ
        content = re.sub(r'([^\n])\n(#{1,6}\s)', r'\1\n\n\2', content)
        content = re.sub(r'(#{1,6}\s[^\n]*)\n([^\n#])', r'\1\n\n\2', content)
        
        # ç¡®ä¿åˆ—è¡¨å‰åæœ‰ç©ºè¡Œ
        content = re.sub(r'([^\n])\n([-*+]\s|[0-9]+\.\s)', r'\1\n\n\2', content)
        
        # ç¡®ä¿å¼•ç”¨å‰åæœ‰ç©ºè¡Œ
        content = re.sub(r'([^\n])\n(>\s)', r'\1\n\n\2', content)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        content = re.sub(r'\n{4,}', '\n\n\n', content)
        content = re.sub(r'\n{3}', '\n\n', content)
        
        return content
    
    def _smart_format_content(self, content):
        """æ™ºèƒ½æ ¼å¼åŒ–å†…å®¹"""
        if not content:
            return ""
        
        # ç¡®ä¿æ ‡é¢˜å±‚çº§æ­£ç¡®ï¼ˆé¿å…ä¸ä¸»æ ‡é¢˜å†²çªï¼‰
        content = re.sub(r'^# ', '## ', content, flags=re.MULTILINE)
        content = re.sub(r'^## ', '### ', content, flags=re.MULTILINE)
        content = re.sub(r'^### ', '#### ', content, flags=re.MULTILINE)
        content = re.sub(r'^#### ', '##### ', content, flags=re.MULTILINE)
        
        # ä¿®å¤ä»£ç å—æ ¼å¼
        content = self._fix_code_blocks(content)
        
        # ä¼˜åŒ–æ®µè½åˆ†éš”
        content = self._optimize_paragraphs(content)
        
        # ä¼˜åŒ–åˆ—è¡¨æ ¼å¼
        content = self._optimize_lists(content)
        
        # æ·»åŠ emojiå¢å¼ºå¯è¯»æ€§
        content = self._add_contextual_emojis(content)
        
        return content
    
    def _fix_code_blocks(self, content):
        """ä¿®å¤ä»£ç å—æ ¼å¼"""
        # ä¿®å¤ä»£ç å—æ ¼å¼ï¼ˆç¡®ä¿å‰åæœ‰ç©ºè¡Œï¼‰
        content = re.sub(r'```(\w*)\n', r'\n```\1\n', content)
        content = re.sub(r'\n```\n', r'\n```\n\n', content)
        
        # ä¿®å¤å†…è”ä»£ç æ ¼å¼ï¼ˆç¡®ä¿å‰åæœ‰é€‚å½“ç©ºæ ¼ï¼‰
        content = re.sub(r'([^\s])`([^`]+)`([^\s])', r'\1 `\2` \3', content)
        
        return content
    
    def _optimize_paragraphs(self, content):
        """ä¼˜åŒ–æ®µè½åˆ†éš”"""
        # ç¡®ä¿æ®µè½ä¹‹é—´æœ‰é€‚å½“çš„ç©ºè¡Œ
        lines = content.split('\n')
        optimized_lines = []
        
        for i, line in enumerate(lines):
            optimized_lines.append(line)
            
            # å¦‚æœå½“å‰è¡Œä¸æ˜¯ç©ºè¡Œï¼Œä¸‹ä¸€è¡Œä¹Ÿä¸æ˜¯ç©ºè¡Œï¼Œä¸”ä¸‹ä¸€è¡Œä¸æ˜¯ç‰¹æ®Šæ ¼å¼
            if (i < len(lines) - 1 and 
                line.strip() and 
                lines[i + 1].strip() and
                not lines[i + 1].startswith(('#', '>', '-', '*', '+', '1.', '```', '|')) and
                not line.startswith(('#', '>', '-', '*', '+', '```', '|'))):
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ ç©ºè¡Œ
                if not any(lines[i + 1].startswith(prefix) for prefix in ['â€¢', 'â”ƒ', 'ã€', 'ã€Š']):
                    optimized_lines.append('')
        
        return '\n'.join(optimized_lines)
    
    def _optimize_lists(self, content):
        """ä¼˜åŒ–åˆ—è¡¨æ ¼å¼"""
        # ç¡®ä¿åˆ—è¡¨é¡¹å‰åæœ‰é€‚å½“çš„ç©ºè¡Œ
        content = re.sub(r'^([-*+â€¢]\s.+)$', r'\n\1', content, flags=re.MULTILINE)
        content = re.sub(r'^(\d+\.\s.+)$', r'\n\1', content, flags=re.MULTILINE)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        return content
    
    def _add_contextual_emojis(self, content):
        """æ ¹æ®ä¸Šä¸‹æ–‡æ·»åŠ emoji"""
        # ä¸ºç‰¹å®šå…³é”®è¯æ®µè½æ·»åŠ emoji
        emoji_patterns = {
            r'^(æ³¨æ„|è­¦å‘Š|é‡è¦)': 'âš ï¸',
            r'^(æŠ€å·§|æŠ€æœ¯|æ–¹æ³•)': 'ğŸ’¡',
            r'^(ç¤ºä¾‹|ä¾‹å­|æ¼”ç¤º)': 'ğŸ’»',
            r'^(æ€»ç»“|ç»“è®º|å°ç»“)': 'ğŸ“‹',
            r'^(ä¼˜ç‚¹|å¥½å¤„|ä¼˜åŠ¿)': 'âœ…',
            r'^(ç¼ºç‚¹|é—®é¢˜|é”™è¯¯)': 'âŒ',
            r'^(æ­¥éª¤|æµç¨‹|è¿‡ç¨‹)': 'ğŸ“'
        }
        
        for pattern, emoji in emoji_patterns.items():
            content = re.sub(pattern, f'{emoji} \\1', content, flags=re.MULTILINE)
        
        return content
    
    def _markdown_to_rich_text_v2(self, markdown_content):
        """ä¼˜åŒ–ç‰ˆMarkdownåˆ°å¯Œæ–‡æœ¬è½¬æ¢ v2.0"""
        if not markdown_content:
            return ""
        
        try:
            # å…ˆè½¬æ¢ä¸ºHTML
            html_content = self.markdown_converter.convert(markdown_content)
            
            # ä½¿ç”¨æ”¹è¿›çš„HTMLåˆ°æ–‡æœ¬è½¬æ¢
            rich_text = self._html_to_formatted_text_v2(html_content)
            
            return rich_text
            
        except Exception as e:
            print(f"âš ï¸ å¯Œæ–‡æœ¬è½¬æ¢å¤±è´¥: {e}")
            return self._markdown_to_plain_text_v2(markdown_content)
    
    def _html_to_formatted_text_v2(self, html_content):
        """æ”¹è¿›ç‰ˆHTMLåˆ°æ ¼å¼åŒ–æ–‡æœ¬è½¬æ¢"""
        if not html_content:
            return ""
        
        # ä½¿ç”¨BeautifulSoupè§£æHTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        def process_element(element, depth=0):
            if isinstance(element, NavigableString):
                text = str(element).strip()
                return text if text else ""
            
            if not hasattr(element, 'name'):
                return ""
            
            tag_name = element.name.lower()
            
            # è·å–æ‰€æœ‰å­å…ƒç´ çš„æ–‡æœ¬
            children_texts = []
            for child in element.children:
                child_text = process_element(child, depth + 1)
                if child_text:
                    children_texts.append(child_text)
            
            content = ' '.join(children_texts) if children_texts else ""
            
            # æ ¹æ®æ ‡ç­¾ç±»å‹æ ¼å¼åŒ–
            if tag_name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                level = int(tag_name[1])
                if content:
                    if level <= 2:
                        return f"\n\n{'=' * 60}\n{'  ' * (level-1)}{content}\n{'=' * 60}\n\n"
                    elif level == 3:
                        return f"\n\nâ–¶ {content}\n{'â”€' * min(len(content), 40)}\n\n"
                    else:
                        return f"\n\nâ— {content}\n\n"
                        
            elif tag_name == 'p':
                if content:
                    return f"\n\n{content}\n\n"
                    
            elif tag_name in ['strong', 'b']:
                return f"**{content}**" if content else ""
                
            elif tag_name in ['em', 'i']:
                return f"*{content}*" if content else ""
                
            elif tag_name == 'code':
                return f"`{content}`" if content else ""
            
            elif tag_name == 'pre':
                if content:
                    # æ£€æµ‹ä»£ç è¯­è¨€
                    code_elem = element.find('code')
                    language = ""
                    if code_elem and code_elem.get('class'):
                        classes = ' '.join(code_elem.get('class', []))
                        lang_match = re.search(r'language-(\w+)', classes)
                        if lang_match:
                            language = lang_match.group(1).upper()
                    
                    if language:
                        return f"\n\nğŸ’» **{language} ä»£ç ç¤ºä¾‹ï¼š**\n```\n{content}\n```\n\n"
                    else:
                        return f"\n\nğŸ’» **ä»£ç ç¤ºä¾‹ï¼š**\n```\n{content}\n```\n\n"
                        
            elif tag_name in ['ul', 'ol']:
                if children_texts:
                    list_content = '\n'.join(children_texts)
                    return f"\n\n{list_content}\n\n"
                    
            elif tag_name == 'li':
                return f"â€¢ {content}" if content else ""
            
            elif tag_name == 'blockquote':
                if content:
                    lines = content.split('\n')
                    quoted_lines = [f"> {line.strip()}" for line in lines if line.strip()]
                    return f"\n\n" + '\n'.join(quoted_lines) + "\n\n"
                    
            elif tag_name == 'a':
                href = element.get('href', '')
                if text_content and href:
                    return f"[{text_content}]({href})"
                else:
                    return text_content
            
            elif tag_name == 'img':
                alt = element.get('alt', 'å›¾ç‰‡')
                src = element.get('src', '')
                if src:
                    return f"\n\n![{alt}]({src})\n\n"
            
            elif tag_name in ['br']:
                return "\n"
            
            elif tag_name in ['hr']:
                return f"\n\n{'â”€' * 50}\n\n"
            
            elif tag_name in ['div', 'section', 'article']:
                # å¯¹äºå®¹å™¨å…ƒç´ ï¼Œè¿”å›å­å…ƒç´ å†…å®¹
                if children_texts:
                    return ' '.join(children_texts)
                else:
                    return text_content
            
            else:
                return text_content
        
        # å¤„ç†æ•´ä¸ªæ–‡æ¡£
        result = process_element(soup)
        
        # åå¤„ç†ï¼šæ¸…ç†æ ¼å¼
        if result:
            # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
            result = re.sub(r'\n{4,}', '\n\n\n', result)
            result = re.sub(r'\n{3}', '\n\n', result)
            
            # ç¡®ä¿ä»£ç å—å‰åæœ‰ç©ºè¡Œ
            result = re.sub(r'([^\n])\n(```)', r'\1\n\n\2', result)
            result = re.sub(r'(```)\n([^\n])', r'\1\n\n\2', result)
            
            # ç¡®ä¿æ ‡é¢˜å‰åæœ‰é€‚å½“ç©ºè¡Œ
            result = re.sub(r'([^\n])\n(â–¶|â—|=)', r'\1\n\n\2', result)
            
            result = result.strip()
        
        return result
    
    def _markdown_to_plain_text_v2(self, markdown_content):
        """æ”¹è¿›ç‰ˆMarkdownåˆ°çº¯æ–‡æœ¬è½¬æ¢ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        if not markdown_content:
            return ""
        
        text = markdown_content
        
        # å¤„ç†æ ‡é¢˜ï¼ˆä¿æŒå±‚çº§ä½†ç¾åŒ–æ ¼å¼ï¼‰
        text = re.sub(r'^#{1}\s+(.+)$', r'\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\1\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{2}\s+(.+)$', r'\n\nâ–¶ \1\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{3,6}\s+(.+)$', r'\n\nâ— \1\n\n', text, flags=re.MULTILINE)
        
        # å¤„ç†ä»£ç å—
        text = re.sub(r'```(\w*)\n(.*?)\n```', r'\n\nğŸ’» **ä»£ç ç¤ºä¾‹ï¼š**\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n\2\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n', text, flags=re.DOTALL)
        
        # å¤„ç†å†…è”ä»£ç 
        text = re.sub(r'`([^`]+)`', r' `\1` ', text)
        
        # å¤„ç†ç²—ä½“å’Œæ–œä½“
        text = re.sub(r'\*\*([^*]+)\*\*', r'**\1**', text)
        text = re.sub(r'\*([^*]+)\*', r'*\1*', text)
        
        # å¤„ç†å¼•ç”¨
        text = re.sub(r'^>\s*(.+)$', r'â”ƒ \1', text, flags=re.MULTILINE)
        
        # å¤„ç†åˆ—è¡¨
        text = re.sub(r'^[-*+]\s+(.+)$', r'â€¢ \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\d+\.\s+(.+)$', r'â€¢ \1', text, flags=re.MULTILINE)
        
        # å¤„ç†é“¾æ¥
        text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'[\1](\2)', text)
        
        # å¤„ç†åˆ†éš”çº¿
        text = re.sub(r'^---+$', 'â”€' * 50, text, flags=re.MULTILINE)
        
        # æœ€ç»ˆæ¸…ç†
        return self._postprocess_text_v2(text)
    
    def save_article_file(self, title, content, tags, url):
        """ä¿å­˜æ–‡ç« åˆ°æ–‡ä»¶"""
        # åˆ›å»ºæ–‡ä»¶åï¼ˆä½¿ç”¨URLçš„hashé¿å…é‡å¤ï¼‰
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        safe_title = re.sub(r'[^\w\s-]', '', title).strip()
        safe_title = re.sub(r'[-\s]+', '-', safe_title)[:50]
        
        filename = f"forwarded-enhanced-{safe_title}-{url_hash}.md"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        today = datetime.now().strftime('%Y-%m-%d')
        target_dir = f"articles/{today}"
        os.makedirs(target_dir, exist_ok=True)
        
        file_path = os.path.join(target_dir, filename)
        
        # å¢å¼ºå†…å®¹æ ¼å¼ï¼ˆä¿å­˜Markdownç‰ˆæœ¬ï¼‰
        enhanced_content = self._enhance_content_format(title, content, url, use_rich_text=False)
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(enhanced_content)
        
        print(f"ğŸ’¾ æ–‡ç« å·²ä¿å­˜: {file_path}")
        return file_path
    
    async def forward_to_toutiao(self, title, content, tags, url, account_file):
        """è½¬å‘æ–‡ç« åˆ°ä»Šæ—¥å¤´æ¡"""
        print("ğŸš€ å¼€å§‹å‘å¸ƒåˆ°ä»Šæ—¥å¤´æ¡...")
        
        try:
            # å¢å¼ºå†…å®¹æ ¼å¼å¹¶è½¬æ¢ä¸ºå¯Œæ–‡æœ¬
            enhanced_content = self._enhance_content_format(title, content, url, use_rich_text=True)
            
            # åˆ›å»ºæ–‡ç« å‘å¸ƒå¯¹è±¡
            article = TouTiaoArticle(
                title=title,
                content=enhanced_content,
                tags=tags,
                publish_date=0,  # ç«‹å³å‘å¸ƒ
                account_file=account_file,
                cover_path=None  # è‡ªåŠ¨ç”Ÿæˆå°é¢
            )
            
            # å‘å¸ƒæ–‡ç« 
            async with async_playwright() as playwright:
                await article.upload(playwright)
            
            print(f"âœ… æ–‡ç« å‘å¸ƒæˆåŠŸ: {title}")
            return True
            
        except Exception as e:
            print(f"âŒ æ–‡ç« å‘å¸ƒå¤±è´¥: {e}")
            return False

async def forward_article_from_url(url, account_file="cookies/toutiao_uploader/account.json", save_file=True):
    """ä»URLè½¬å‘æ–‡ç« åˆ°ä»Šæ—¥å¤´æ¡"""
    print("ğŸ”— å¢å¼ºç‰ˆæ–‡ç« é“¾æ¥è½¬å‘å·¥å…· v2.1")
    print("=" * 60)
    
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    print("ğŸ” æ£€æŸ¥ç™»å½•çŠ¶æ€...")
    if not await toutiao_setup(account_file):
        print("âŒ ç™»å½•çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆç™»å½•")
        print("è¿è¡Œä»¥ä¸‹å‘½ä»¤é‡æ–°ç™»å½•:")
        print("python examples/login_toutiao.py")
        return False
    
    print("âœ… ç™»å½•çŠ¶æ€æ­£å¸¸")
    
    # åˆ›å»ºè½¬å‘å™¨
    forwarder = EnhancedArticleForwarder()
    
    # è·å–æ–‡ç« å†…å®¹
    title, content, tags = await forwarder.fetch_article(url)
    
    if not title or not content:
        print("âŒ æ— æ³•è·å–æ–‡ç« å†…å®¹")
        return False
    
    # ä¿å­˜æ–‡ç« æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    if save_file:
        file_path = forwarder.save_article_file(title, content, tags, url)
    
    # ç¡®è®¤å‘å¸ƒ
    print(f"\nâš ï¸ å³å°†è½¬å‘æ–‡ç« åˆ°ä»Šæ—¥å¤´æ¡:")
    print(f"ğŸ“° æ ‡é¢˜: {title}")
    print(f"ğŸ“Š å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    print(f"ğŸ·ï¸ æ ‡ç­¾: {tags}")
    print(f"ğŸ”— æ¥æº: {url}")
    print(f"ğŸ¨ æ’ç‰ˆ: å·²å¯ç”¨å¢å¼ºæ’ç‰ˆæ¨¡å¼")
    print(f"ğŸ”„ æ ¼å¼: Markdown â†’ å¯Œæ–‡æœ¬æ ¼å¼")
    print(f"ğŸ”’ éªŒè¯ç : å¦‚é‡éªŒè¯ç å°†ç­‰å¾…ç”¨æˆ·è¾“å…¥")
    
    try:
        confirm = input("\nç¡®è®¤è½¬å‘å—ï¼Ÿ(y/N): ").strip().lower()
        if confirm not in ['y', 'yes']:
            print("âŒ ç”¨æˆ·å–æ¶ˆè½¬å‘")
            return False
    except EOFError:
        # å¤„ç†ç®¡é“è¾“å…¥çš„æƒ…å†µ
        print("\nğŸ“‹ æ£€æµ‹åˆ°éäº¤äº’æ¨¡å¼ï¼Œè‡ªåŠ¨ç¡®è®¤è½¬å‘")
        print("âš ï¸ æ³¨æ„: å¦‚é‡éªŒè¯ç ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨è¾“å…¥")
    
    # è½¬å‘åˆ°ä»Šæ—¥å¤´æ¡
    success = await forwarder.forward_to_toutiao(title, content, tags, url, account_file)
    
    if success:
        print("\nğŸ‰ æ–‡ç« è½¬å‘å®Œæˆï¼")
        print("ğŸ“± è¯·ç™»å½•ä»Šæ—¥å¤´æ¡æŸ¥çœ‹å‘å¸ƒç»“æœ")
        print("âœ¨ æ’ç‰ˆå·²ä¼˜åŒ–ï¼Œé˜…è¯»ä½“éªŒæ›´ä½³")
        print("ğŸ”„ å†…å®¹å·²è½¬æ¢ä¸ºå¯Œæ–‡æœ¬æ ¼å¼ï¼Œæ— HTMLä»£ç ")
    else:
        print("\nâŒ æ–‡ç« è½¬å‘å¤±è´¥")
    
    return success

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆæ–‡ç« é“¾æ¥è½¬å‘åˆ°ä»Šæ—¥å¤´æ¡å·¥å…· v3.0 (wechatSyncé£æ ¼)')
    parser.add_argument('url', help='è¦è½¬å‘çš„æ–‡ç« é“¾æ¥')
    parser.add_argument('--account', default='cookies/toutiao_uploader/account.json', help='è´¦å·cookieæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-save', action='store_true', help='ä¸ä¿å­˜æ–‡ç« åˆ°æœ¬åœ°æ–‡ä»¶')
    parser.add_argument('--preview', action='store_true', help='ä»…é¢„è§ˆæ ¼å¼åŒ–æ•ˆæœï¼Œä¸å‘å¸ƒåˆ°å¤´æ¡')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥URLæ ¼å¼
    if not args.url.startswith(('http://', 'https://')):
        print("âŒ è¯·æä¾›æœ‰æ•ˆçš„URLé“¾æ¥")
        return
    
    # å¦‚æœæ˜¯é¢„è§ˆæ¨¡å¼ï¼Œä¸æ£€æŸ¥è´¦å·æ–‡ä»¶
    if not args.preview:
        # æ£€æŸ¥è´¦å·æ–‡ä»¶
        if not os.path.exists(args.account):
            print(f"âŒ è´¦å·æ–‡ä»¶ä¸å­˜åœ¨: {args.account}")
            print("è¯·å…ˆè¿è¡Œç™»å½•è„šæœ¬: python examples/login_toutiao.py")
            return
    
    print(f"ğŸ”— ç›®æ ‡é“¾æ¥: {args.url}")
    if not args.preview:
        print(f"ğŸ”‘ è´¦å·æ–‡ä»¶: {args.account}")
    print(f"ğŸ’¾ ä¿å­˜æ–‡ä»¶: {'å¦' if args.no_save else 'æ˜¯'}")
    print(f"ğŸ‘€ é¢„è§ˆæ¨¡å¼: {'æ˜¯' if args.preview else 'å¦'}")
    print(f"âœ¨ ç‰ˆæœ¬: WechatSyncé£æ ¼æ’ç‰ˆ v3.0 (å¢å¼ºä»£ç å—ã€æ ‡é¢˜ç¾åŒ–)")
    
    # è¿è¡Œè½¬å‘æˆ–é¢„è§ˆ
    if args.preview:
        asyncio.run(preview_article_format(args.url, not args.no_save))
    else:
        asyncio.run(forward_article_from_url(args.url, args.account, not args.no_save))

async def preview_article_format(url, save_file=True):
    """é¢„è§ˆæ–‡ç« æ ¼å¼åŒ–æ•ˆæœ"""
    print("ğŸ‘ï¸ æ–‡ç« æ ¼å¼åŒ–é¢„è§ˆæ¨¡å¼")
    print("=" * 60)
    
    # åˆ›å»ºè½¬å‘å™¨
    forwarder = EnhancedArticleForwarder()
    
    # è·å–æ–‡ç« å†…å®¹
    title, content, tags = await forwarder.fetch_article(url)
    
    if not title or not content:
        print("âŒ æ— æ³•è·å–æ–‡ç« å†…å®¹")
        return False
    
    # ä¿å­˜æ–‡ç« æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    if save_file:
        file_path = forwarder.save_article_file(title, content, tags, url)
        print(f"ğŸ“ é¢„è§ˆæ–‡ä»¶å·²ä¿å­˜: {file_path}")
    
    # ç”Ÿæˆæ ¼å¼åŒ–å†…å®¹é¢„è§ˆ
    print(f"\nğŸ“ æ–‡ç« æ ¼å¼åŒ–é¢„è§ˆ:")
    print(f"ğŸ“° æ ‡é¢˜: {title}")
    print(f"ğŸ“Š åŸå§‹å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    print(f"ğŸ·ï¸ æ ‡ç­¾: {tags}")
    print("=" * 60)
    
    # å¢å¼ºå†…å®¹æ ¼å¼å¹¶æ˜¾ç¤º
    enhanced_content = forwarder._enhance_content_format(title, content, url, use_rich_text=True)
    
    print("\nğŸ¨ æ ¼å¼åŒ–åå†…å®¹é¢„è§ˆ:")
    print("â”€" * 60)
    print(enhanced_content[:1000] + "..." if len(enhanced_content) > 1000 else enhanced_content)
    if len(enhanced_content) > 1000:
        print(f"\n... (å†…å®¹å¤ªé•¿ï¼Œä»…æ˜¾ç¤ºå‰1000å­—ç¬¦ï¼Œå®Œæ•´å†…å®¹å…±{len(enhanced_content)}å­—ç¬¦)")
    print("â”€" * 60)
    
    print("\nâœ¨ æ ¼å¼åŒ–ç‰¹æ€§è¯´æ˜:")
    print("  ğŸ“– æ ‡é¢˜: ä½¿ç”¨emojiå’Œåˆ†éš”çº¿ç¾åŒ–")
    print("  ğŸ’» ä»£ç å—: å¸¦è¾¹æ¡†å’Œè¯­è¨€æ ‡è¯†")
    print("  ğŸ”¹ æ®µè½: é€‚å½“é—´è·å’Œå±‚çº§ç»“æ„")
    print("  ğŸ“ åˆ—è¡¨: ä½¿ç”¨ç¾è§‚çš„é¡¹ç›®ç¬¦å·")
    print("  ğŸ’¡ å¼•ç”¨: å¸¦ç«–çº¿å’Œemojiè£…é¥°")
    print("  ğŸ”— é“¾æ¥: ä¿ç•™åŸå§‹é“¾æ¥æ ¼å¼")
    
    print(f"\nğŸ¯ é¢„è§ˆå®Œæˆï¼å¦‚éœ€å‘å¸ƒåˆ°å¤´æ¡ï¼Œè¯·ç§»é™¤ --preview å‚æ•°")
    return True

if __name__ == "__main__":
    main() 