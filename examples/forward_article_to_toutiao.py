#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ–‡ç« é“¾æ¥è½¬å‘åˆ°ä»Šæ—¥å¤´æ¡å·¥å…· v2.0
æ”¯æŒä»å„ç§ç½‘ç«™æŠ“å–æ–‡ç« å†…å®¹å¹¶è½¬å‘åˆ°ä»Šæ—¥å¤´æ¡
ä¼˜åŒ–æ’ç‰ˆï¼Œæå‡é˜…è¯»ä½“éªŒ
"""

import asyncio
import os
import sys
import re
import time
import hashlib
import textwrap
from datetime import datetime
from urllib.parse import urlparse
from playwright.async_api import async_playwright
import requests
from bs4 import BeautifulSoup, NavigableString, Tag
import markdown
import openai
from typing import Optional, Dict, List
import json
import argparse
import traceback
import math
import random
import logging
import types

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from uploader.toutiao_uploader.main_final import TouTiaoArticle, toutiao_setup

logger = logging.getLogger("toutiao_forward")
logger.setLevel(logging.INFO)
if not logger.handlers:
    from logging.handlers import RotatingFileHandler
    handler = RotatingFileHandler("/Users/yongjun.xiao/Downloads/workspace/python/social-auto-upload/logs/toutiao_forward_debug.log", maxBytes=5*1024*1024, backupCount=2)
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

logger.info(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
logger.info(f"logs ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists('logs')}")

class WechatSyncStyleFormatter:
    """ä¼˜åŒ–ç‰ˆæ ¼å¼åŒ–å™¨ - è§£å†³ç©ºè¡Œè¿‡å¤šã€ä»£ç å—æ˜¾ç¤ºå’Œmarkdownæ¸²æŸ“é—®é¢˜"""
    
    def __init__(self):
        self.code_languages = {
            'javascript': 'JavaScript', 'js': 'JavaScript',
            'typescript': 'TypeScript', 'ts': 'TypeScript', 
            'python': 'Python', 'py': 'Python',
            'java': 'Java', 'cpp': 'C++', 'c': 'C',
            'html': 'HTML', 'css': 'CSS', 'scss': 'SCSS',
            'shell': 'Shell', 'bash': 'Bash', 'sql': 'SQL',
            'json': 'JSON', 'xml': 'XML', 'yaml': 'YAML'
        }
        self.markdown_converter = markdown.Markdown(extensions=['fenced_code', 'tables'])
    
    def _simple_markdown_to_text(self, text):
        """ç®€åŒ–çš„Markdownåˆ°æ–‡æœ¬è½¬æ¢ - ä¼˜åŒ–ç‰ˆ"""
        if not text:
            return ""
        
        # å¤„ç†æ²¡æœ‰ç©ºæ ¼çš„æ ‡é¢˜æ ¼å¼ï¼ˆä¾‹å¦‚ "##å‰è¨€" å˜æˆ "## å‰è¨€"ï¼‰
        text = re.sub(r'^(#{1,6})([^#\s])', r'\1 \2', text, flags=re.MULTILINE)
        
        # å¤„ç†æ ‡é¢˜
        text = re.sub(r'^#{1}\s+(.+)$', r'\n# \1\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{2}\s+(.+)$', r'\n## \1\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{3}\s+(.+)$', r'\n### \1\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{4}\s+(.+)$', r'\n#### \1\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{5,6}\s+(.+)$', r'\n##### \1\n', text, flags=re.MULTILINE)
        
        # å¤„ç†ä»£ç å—
        def replace_code_block(match):
            language = match.group(1) if match.group(1) else ''
            code = match.group(2)
            return self._format_code_block(code, language)
        
        text = re.sub(r'```(\w*)\n(.*?)\n```', replace_code_block, text, flags=re.DOTALL)
        
        # å¤„ç†å†…è”ä»£ç 
        text = re.sub(r'`([^`]+)`', r'`\1`', text)
        
        # å¤„ç†ç²—ä½“å’Œæ–œä½“
        text = re.sub(r'\*\*([^*]+)\*\*', r'**\1**', text)
        text = re.sub(r'\*([^*]+)\*', r'*\1*', text)
        
        # å¤„ç†å¼•ç”¨
        text = re.sub(r'^>\s*(.+)$', r'> \1', text, flags=re.MULTILINE)
        
        # å¤„ç†åˆ—è¡¨
        text = re.sub(r'^[-*+]\s+(.+)$', r'- \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\d+\.\s+(.+)$', r'1. \1', text, flags=re.MULTILINE)
        
        # å¤„ç†é“¾æ¥
        text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'\1', text)
        
        # å¤„ç†åˆ†éš”çº¿
        text = re.sub(r'^---+$', '---', text, flags=re.MULTILINE)
        
        # åå¤„ç†
        return self._postprocess_text(text)
    
    def html_to_text(self, html_content):
        """å°†HTMLè½¬æ¢ä¸ºæ¸…æ™°çš„æ–‡æœ¬æ ¼å¼ - ä¼˜åŒ–ç‰ˆ"""
        if not html_content:
            return ""
        
        # ä½¿ç”¨BeautifulSoupè§£æ
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ 
        for tag in soup(['script', 'style', 'meta', 'link', 'noscript', 'nav', 'header', 'footer']):
            tag.decompose()
        
        # å¤„ç†ç‰¹æ®Šå…ƒç´ 
        self._preprocess_elements(soup)
        
        # è½¬æ¢ä¸ºæ–‡æœ¬
        result = self._element_to_text(soup)
        
        # åå¤„ç† - ä¼˜åŒ–æ ¼å¼
        return self._postprocess_text(result)
    
    def _preprocess_elements(self, soup):
        """é¢„å¤„ç†HTMLå…ƒç´ """
        # å¤„ç†ä»£ç å—
        for pre in soup.find_all('pre'):
            code = pre.find('code')
            if code:
                language = self._detect_language(code)
                code_text = code.get_text()
                # åˆ›å»ºç‰¹æ®Šæ ‡è®°
                marker = soup.new_tag('div')
                marker['data-type'] = 'codeblock'
                marker['data-language'] = language
                marker.string = code_text
                pre.replace_with(marker)
        
        # å¤„ç†å†…è”ä»£ç 
        for code in soup.find_all('code'):
            if code.parent.name != 'pre':
                code_text = code.get_text()
                marker = soup.new_tag('span')
                marker['data-type'] = 'inline-code'
                marker.string = code_text
                code.replace_with(marker)
        
        # å¤„ç†é“¾æ¥
        for a in soup.find_all('a'):
            href = a.get('href', '')
            text = a.get_text().strip()
            if text and href:
                marker = soup.new_tag('span')
                marker['data-type'] = 'link'
                marker['data-href'] = href
                marker.string = text
                a.replace_with(marker)
    
    def _detect_language(self, code_elem):
        """æ£€æµ‹ä»£ç è¯­è¨€"""
        classes = code_elem.get('class', [])
        if isinstance(classes, list):
            for cls in classes:
                if cls.startswith('language-'):
                    lang = cls.replace('language-', '')
                    return self.code_languages.get(lang, lang.title())
                elif cls.startswith('lang-'):
                    lang = cls.replace('lang-', '')
                    return self.code_languages.get(lang, lang.title())
        
        # å°è¯•ä»çˆ¶å…ƒç´ è·å–è¯­è¨€ä¿¡æ¯
        parent = code_elem.parent
        if parent and parent.get('class'):
            for cls in parent.get('class', []):
                if cls.startswith('language-'):
                    lang = cls.replace('language-', '')
                    return self.code_languages.get(lang, lang.title())
        
        return ''
    
    def _element_to_text(self, element):
        """å°†å…ƒç´ è½¬æ¢ä¸ºæ–‡æœ¬ - ä¼˜åŒ–ç‰ˆ"""
        if isinstance(element, NavigableString):
            return str(element).strip()
        
        if not hasattr(element, 'name'):
            return ""
        
        tag = element.name.lower()
        
        # å¤„ç†ç‰¹æ®Šæ•°æ®ç±»å‹
        if tag == 'div' and element.get('data-type') == 'codeblock':
            language = element.get('data-language', '')
            code_text = element.get_text()
            return self._format_code_block(code_text, language)
        
        elif tag == 'span' and element.get('data-type') == 'inline-code':
            return f"`{element.get_text()}`"
        
        elif tag == 'span' and element.get('data-type') == 'link':
            text = element.get_text()
            href = element.get('data-href', '')
            return f"{text}"  # ä¸æ˜¾ç¤ºé“¾æ¥URLï¼Œä¿æŒæ–‡ç« æ•´æ´
        
        # å¤„ç†å­å…ƒç´ 
        children_text = []
        for child in element.children:
            child_text = self._element_to_text(child)
            if child_text:
                children_text.append(child_text)
        
        text = ' '.join(children_text) if children_text else element.get_text().strip()
        
        # æ ¹æ®æ ‡ç­¾æ ¼å¼åŒ– - ä¼˜åŒ–ç‰ˆ
        if tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            level = int(tag[1])
            return self._format_heading(text, level)
        
        elif tag == 'p':
            return text + "\n\n" if text else ""
        
        elif tag in ['strong', 'b']:
            return f"**{text}**" if text else ""
        
        elif tag in ['em', 'i']:
            return f"*{text}*" if text else ""
        
        elif tag in ['ul', 'ol']:
            return self._format_list(element, tag)
        
        elif tag == 'li':
            return text
        
        elif tag == 'blockquote':
            return self._format_quote(text)
        
        elif tag == 'br':
            return "\n"
        
        elif tag == 'hr':
            return "\n---\n"
        
        elif tag in ['div', 'section', 'article']:
            return text + "\n\n" if text else ""
        
        elif tag == 'table':
            return self._format_table(element)
        
        else:
            return text
    
    def _format_heading(self, text, level):
        """æ ¼å¼åŒ–æ ‡é¢˜ - ä¼˜åŒ–ç‰ˆ"""
        if not text:
            return ""
        
        text = text.strip()
        prefix = "#" * level
        
        # ä¸ºæ ‡é¢˜æ·»åŠ è¡¨æƒ…ç¬¦å·ï¼Œä½¿å…¶æ›´åŠ é†’ç›®
        if level <= 3 and len(text) < 30:  # åªä¸ºè¾ƒçŸ­çš„ä¸»è¦æ ‡é¢˜æ·»åŠ è¡¨æƒ…ç¬¦å·
            for keyword, emoji in self.code_languages.items():
                if keyword.lower() in text.lower():
                    text = f"{emoji} {text}"
                    break
        
        # ç¡®ä¿æ ‡é¢˜å‰åæœ‰è¶³å¤Ÿçš„ç©ºè¡Œ
        return f"\n\n{prefix} {text}\n\n"
    
    def _format_code_block(self, code_text, language=''):
        """æ ¼å¼åŒ–ä»£ç å— - ä¼˜åŒ–ç‰ˆ"""
        if not code_text:
            return ""
        
        code_text = code_text.strip()
        lang_text = f" ({language})" if language else ""
        
        return f"\n```{language.lower()}\n{code_text}\n```\n\n"
    
    def _format_list(self, element, list_type):
        """æ ¼å¼åŒ–åˆ—è¡¨ - ä¼˜åŒ–ç‰ˆ"""
        items = []
        index = 1
        
        for li in element.find_all('li', recursive=False):
            text = self._element_to_text(li).strip()
            if text:
                if list_type == 'ol':
                    items.append(f"{index}. {text}")
                    index += 1
                else:
                    items.append(f"- {text}")
        
        return "\n" + "\n".join(items) + "\n\n" if items else ""
    
    def _format_quote(self, text):
        """æ ¼å¼åŒ–å¼•ç”¨å— - ä¼˜åŒ–ç‰ˆ"""
        if not text:
            return ""
        
        lines = text.strip().split('\n')
        quoted_lines = [f"> {line.strip()}" for line in lines if line.strip()]
        
        return "\n" + "\n".join(quoted_lines) + "\n\n"
    
    def _format_table(self, table_element):
        """æ ¼å¼åŒ–è¡¨æ ¼ - ä¼˜åŒ–ç‰ˆ"""
        rows = []
        header_cells = []
        
        # å¤„ç†è¡¨å¤´
        header_row = table_element.find('tr')
        if header_row:
            for th in header_row.find_all(['th', 'td']):
                text = th.get_text().strip()
                header_cells.append(text)
            
            if header_cells:
                rows.append("| " + " | ".join(header_cells) + " |")
                rows.append("| " + " | ".join(['---'] * len(header_cells)) + " |")
        
        # å¤„ç†æ•°æ®è¡Œ
        for tr in table_element.find_all('tr')[1:]:
            cells = []
            for td in tr.find_all('td'):
                text = td.get_text().strip()
                cells.append(text)
            if cells:
                rows.append("| " + " | ".join(cells) + " |")
        
        return "\n" + "\n".join(rows) + "\n\n" if rows else ""
    
    def _postprocess_text(self, text):
        """åå¤„ç†æ–‡æœ¬ - ä¼˜åŒ–ç‰ˆ"""
        if not text:
            return ""
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # ç¡®ä¿ä»£ç å—å‰åæœ‰ç©ºè¡Œ
        text = re.sub(r'([^\n])\n```', r'\1\n\n```', text)
        text = re.sub(r'```\n([^\n])', r'```\n\n\1', text)
        
        # ç¡®ä¿æ ‡é¢˜å‰åæœ‰ç©ºè¡Œ
        text = re.sub(r'([^\n])\n(#{1,6} )', r'\1\n\n\2', text)
        text = re.sub(r'(#{1,6} .*)\n([^\n])', r'\1\n\n\2', text)
        
        # ç¡®ä¿å¼•ç”¨å—å‰åæœ‰ç©ºè¡Œ
        text = re.sub(r'([^\n])\n>', r'\1\n\n>', text)
        text = re.sub(r'>\s*\n([^\n>])', r'>\n\n\1', text)
        
        # ç¡®ä¿åˆ—è¡¨é¡¹ä¹‹é—´æ²¡æœ‰ç©ºè¡Œï¼Œä½†åˆ—è¡¨å‰åæœ‰ç©ºè¡Œ
        text = re.sub(r'\n\n([-*+]|\d+\.)\s', r'\n\1 ', text)
        text = re.sub(r'([^\n])\n([-*+]|\d+\.)\s', r'\1\n\n\2 ', text)
        text = re.sub(r'([-*+]|\d+\.)\s.*\n([^\n-*+\d])', r'\1\n\n\2', text)
        
        return text.strip()
    
    def markdown_to_text(self, markdown_content):
        """å°†Markdownè½¬æ¢ä¸ºä¼˜åŒ–çš„æ–‡æœ¬æ ¼å¼"""
        if not markdown_content:
            return ""
        
        try:
            # å°†Markdownè½¬æ¢ä¸ºHTML
            html_content = self.markdown_converter.convert(markdown_content)
            
            # å°†HTMLè½¬æ¢ä¸ºä¼˜åŒ–çš„æ–‡æœ¬æ ¼å¼
            return self.html_to_text(html_content)
        except Exception as e:
            print(f"âš ï¸ Markdownè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–è½¬æ¢: {e}")
            return self._simple_markdown_to_text(markdown_content)

class EnhancedArticleForwarder:
    """å¢å¼ºç‰ˆæ–‡ç« è½¬å‘å·¥å…·"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        self.site_configs = {
            'juejin.cn': self._extract_juejin,
            'cnblogs.com': self._extract_cnblogs,
            'csdn.net': self._extract_csdn,
            'jianshu.com': self._extract_jianshu,
            'zhihu.com': self._extract_zhihu,
            'segmentfault.com': self._extract_segmentfault,
            'oschina.net': self._extract_oschina,
        }
        
        # åˆå§‹åŒ–æ ¼å¼åŒ–å™¨
        self.formatter = WechatSyncStyleFormatter()
        
        # å†…å®¹ç¾åŒ–é…ç½®
        self.content_enhancers = {
            'emoji_mapping': {
                'å‰è¨€': 'ğŸ“', 'ä»‹ç»': 'ğŸ“–', 'æ¦‚è¿°': 'ğŸ”',
                'å®‰è£…': 'âš™ï¸', 'é…ç½®': 'ğŸ”§', 'ä½¿ç”¨': 'ğŸš€',
                'ç¤ºä¾‹': 'ğŸ’¡', 'ä¾‹å­': 'ğŸ’¡', 'ä»£ç ': 'ğŸ’»',
                'æ€»ç»“': 'ğŸ“‹', 'ç»“è®º': 'ğŸ¯', 'å°ç»“': 'ğŸ“',
                'æ³¨æ„': 'âš ï¸', 'è­¦å‘Š': 'ğŸš¨', 'æç¤º': 'ğŸ’¡',
                'ä¼˜ç‚¹': 'âœ…', 'ç¼ºç‚¹': 'âŒ', 'ç‰¹ç‚¹': 'ğŸ¯',
                'æ­¥éª¤': 'ğŸ“', 'æ–¹æ³•': 'ğŸ”§', 'æŠ€å·§': 'ğŸ’¡',
                'é—®é¢˜': 'â“', 'è§£å†³': 'âœ…', 'é”™è¯¯': 'âŒ',
                'æ€§èƒ½': 'âš¡', 'å®‰å…¨': 'ğŸ”’', 'æµ‹è¯•': 'ğŸ§ª'
            },
            'code_languages': {
                'python': 'Python',
                'java': 'Java',
                'javascript': 'JavaScript',
                'js': 'JavaScript',
                'typescript': 'TypeScript',
                'ts': 'TypeScript',
                'html': 'HTML',
                'css': 'CSS',
                'php': 'PHP',
                'ruby': 'Ruby',
                'go': 'Go',
                'rust': 'Rust',
                'c': 'C',
                'cpp': 'C++',
                'csharp': 'C#',
                'swift': 'Swift',
                'kotlin': 'Kotlin',
                'sql': 'SQL',
                'bash': 'Bash',
                'shell': 'Shell',
                'json': 'JSON',
                'xml': 'XML',
                'yaml': 'YAML',
                'markdown': 'Markdown',
                'md': 'Markdown',
                'plaintext': 'çº¯æ–‡æœ¬',
                'text': 'çº¯æ–‡æœ¬'
            }
        }
    
    def _markdown_to_html(self, markdown_content):
        """å°†Markdownå†…å®¹è½¬æ¢ä¸ºHTML"""
        if not markdown_content:
            return ""
        
        try:
            # é‡ç½®è½¬æ¢å™¨çŠ¶æ€
            self.markdown_converter.reset()
            
            # è½¬æ¢Markdownä¸ºHTML
            html_content = self.markdown_converter.convert(markdown_content)
            
            # ä¼˜åŒ–HTMLæ ¼å¼
            html_content = self._optimize_html_format(html_content)
            
            return html_content
            
        except Exception as e:
            print(f"âš ï¸ Markdownè½¬æ¢å¤±è´¥: {e}")
            return markdown_content
    
    def _optimize_html_format(self, html_content):
        """ä¼˜åŒ–HTMLæ ¼å¼"""
        if not html_content:
            return ""
        
        # ä¸ºæ®µè½æ·»åŠ é—´è·
        html_content = re.sub(r'<p>', '<p style="margin: 16px 0; line-height: 1.6;">', html_content)
        
        # ä¸ºæ ‡é¢˜æ·»åŠ æ ·å¼
        html_content = re.sub(r'<h1>', '<h1 style="font-size: 24px; font-weight: bold; margin: 24px 0 16px 0; color: #333;">', html_content)
        html_content = re.sub(r'<h2>', '<h2 style="font-size: 22px; font-weight: bold; margin: 20px 0 14px 0; color: #333; border-bottom: 2px solid #eee; padding-bottom: 8px;">', html_content)
        html_content = re.sub(r'<h3>', '<h3 style="font-size: 20px; font-weight: bold; margin: 18px 0 12px 0; color: #333;">', html_content)
        html_content = re.sub(r'<h4>', '<h4 style="font-size: 18px; font-weight: bold; margin: 16px 0 10px 0; color: #333;">', html_content)
        html_content = re.sub(r'<h5>', '<h5 style="font-size: 16px; font-weight: bold; margin: 14px 0 8px 0; color: #333;">', html_content)
        html_content = re.sub(r'<h6>', '<h6 style="font-size: 14px; font-weight: bold; margin: 12px 0 6px 0; color: #333;">', html_content)
        
        # ä¸ºé“¾æ¥æ·»åŠ æ ·å¼
        html_content = re.sub(r'<a ', '<a style="color: #1890ff; text-decoration: none;" ', html_content)
        
        # ä¸ºå¼ºè°ƒæ–‡æœ¬æ·»åŠ æ ·å¼
        html_content = re.sub(r'<strong>', '<strong style="font-weight: bold; color: #333;">', html_content)
        html_content = re.sub(r'<em>', '<em style="font-style: italic; color: #666;">', html_content)
        
        # ä¸ºä»£ç æ·»åŠ æ ·å¼
        html_content = re.sub(
            r'<code>',
            '<code style="background-color: #f6f8fa; color: #d73a49; padding: 2px 4px; border-radius: 3px; font-family: monospace; font-size: 0.9em;">',
            html_content
        )
        
        # ä¸ºä»£ç å—æ·»åŠ æ ·å¼
        html_content = re.sub(
            r'<pre>',
            '<pre style="background-color: #f6f8fa; border: 1px solid #e1e4e8; border-radius: 6px; padding: 16px; overflow-x: auto; margin: 16px 0; font-family: monospace; font-size: 14px; line-height: 1.45;">',
            html_content
        )
        
        # ä¸ºå¼•ç”¨å—æ·»åŠ æ ·å¼
        html_content = re.sub(
            r'<blockquote>',
            '<blockquote style="border-left: 4px solid #dfe2e5; margin: 16px 0; padding: 0 16px; color: #6a737d; background-color: #f8f9fa; border-radius: 0 6px 6px 0;">',
            html_content
        )
        
        # ä¸ºåˆ—è¡¨æ·»åŠ æ ·å¼
        html_content = re.sub(r'<ul>', '<ul style="margin: 16px 0; padding-left: 24px;">', html_content)
        html_content = re.sub(r'<ol>', '<ol style="margin: 16px 0; padding-left: 24px;">', html_content)
        html_content = re.sub(r'<li>', '<li style="margin: 4px 0; line-height: 1.6;">', html_content)
        
        # ä¸ºè¡¨æ ¼æ·»åŠ æ ·å¼
        html_content = re.sub(r'<table>', '<table style="border-collapse: collapse; width: 100%; border: 1px solid #e1e4e8; margin: 16px 0;">', html_content)
        html_content = re.sub(r'<th>', '<th style="background-color: #f6f8fa; border: 1px solid #e1e4e8; padding: 8px 12px; text-align: left; font-weight: bold;">', html_content)
        html_content = re.sub(r'<td>', '<td style="border: 1px solid #e1e4e8; padding: 8px 12px;">', html_content)
        
        return html_content
    
    def _markdown_to_rich_text(self, markdown_content):
        """å°†Markdownå†…å®¹è½¬æ¢ä¸ºå¯Œæ–‡æœ¬æ ¼å¼ï¼ˆä¸æ˜¯HTMLä»£ç ï¼‰"""
        if not markdown_content:
            return ""
        
        try:
            # å…ˆè½¬æ¢ä¸ºHTML
            html_content = self.markdown_converter.convert(markdown_content)
            
            # å°†HTMLè½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼Œä½†ä¿ç•™æ ¼å¼æ•ˆæœ
            rich_text = self._html_to_formatted_text(html_content)
            
            return rich_text
            
        except Exception as e:
            print(f"âš ï¸ å¯Œæ–‡æœ¬è½¬æ¢å¤±è´¥: {e}")
            return self._markdown_to_plain_text(markdown_content)
    
    def _html_to_formatted_text(self, html_content):
        """å°†HTMLè½¬æ¢ä¸ºæ ¼å¼åŒ–çš„çº¯æ–‡æœ¬"""
        if not html_content:
            return ""
        
        # ä½¿ç”¨BeautifulSoupè§£æHTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # é€’å½’å¤„ç†HTMLå…ƒç´ ï¼Œè½¬æ¢ä¸ºæ ¼å¼åŒ–æ–‡æœ¬
        def process_html_element(element, depth=0):
            if isinstance(element, NavigableString):
                return str(element).strip()
            
            if not hasattr(element, 'name'):
                return ""
            
            tag_name = element.name.lower()
            
            # è·å–å­å…ƒç´ å†…å®¹
            children_text = []
            for child in element.children:
                child_text = process_html_element(child, depth + 1)
                if child_text:
                    children_text.append(child_text)
            
            content = ' '.join(children_text) if children_text else element.get_text().strip()
            
            # æ ¹æ®HTMLæ ‡ç­¾è½¬æ¢ä¸ºç›¸åº”çš„æ–‡æœ¬æ ¼å¼
            if tag_name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                level = int(tag_name[1])
                if content:
                    return f"\n\n{content}\n\n"
            
            elif tag_name == 'p':
                return f"\n\n{content}\n\n"
            
            elif tag_name in ['strong', 'b']:
                return content  # ä¸æ·»åŠ ç‰¹æ®Šæ ‡è®°ï¼Œä¾èµ–ç¼–è¾‘å™¨çš„å¯Œæ–‡æœ¬åŠŸèƒ½
            
            elif tag_name in ['em', 'i']:
                return content  # ä¸æ·»åŠ ç‰¹æ®Šæ ‡è®°ï¼Œä¾èµ–ç¼–è¾‘å™¨çš„å¯Œæ–‡æœ¬åŠŸèƒ½
            
            elif tag_name == 'code':
                if content:
                    return content  # ä¸æ·»åŠ ç‰¹æ®Šæ ‡è®°ï¼Œä¾èµ–ç¼–è¾‘å™¨çš„å¯Œæ–‡æœ¬åŠŸèƒ½
            
            elif tag_name == 'pre':
                if content:
                    return f"\n\n{content}\n\n"
            
            elif tag_name in ['ul', 'ol']:
                if children_text:
                    return f"\n\n" + "\n".join(children_text) + "\n\n"
            
            elif tag_name == 'li':
                if content:
                    return f"â€¢ {content}"
            
            elif tag_name == 'blockquote':
                if content:
                    return f"\n\n{content}\n\n"
            
            elif tag_name == 'a':
                href = element.get('href', '')
                if content and href:
                    return content  # ä¸æ˜¾ç¤ºé“¾æ¥URLï¼Œä¿æŒæ–‡ç« æ•´æ´
                else:
                    return content
            
            elif tag_name == 'table':
                return f"\n\n{content}\n\n"
            
            elif tag_name in ['th', 'td']:
                return f"{content} |"
            
            elif tag_name == 'tr':
                return f"|{content}\n"
            
            elif tag_name == 'hr':
                return "\n\n---\n\n"
            
            elif tag_name == 'br':
                return "\n"
            
            else:
                return content
        
        # å¤„ç†æ•´ä¸ªHTMLæ–‡æ¡£
        result = process_html_element(soup)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œå’Œç©ºæ ¼
        if result:
            result = re.sub(r'\n{3,}', '\n\n', result)  # å°†3ä¸ªä»¥ä¸Šçš„æ¢è¡Œæ›¿æ¢ä¸º2ä¸ª
            result = re.sub(r'[ \t]+', ' ', result)  # å°†å¤šä¸ªç©ºæ ¼æ›¿æ¢ä¸º1ä¸ª
            result = result.strip()
        
        return result
    
    def _markdown_to_plain_text(self, markdown_content):
        """å°†Markdownè½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        if not markdown_content:
            return ""
        
        # ç®€å•çš„Markdownåˆ°æ–‡æœ¬è½¬æ¢
        text = markdown_content
        
        # å¤„ç†æ ‡é¢˜
        text = re.sub(r'^#{1}\s+(.+)$', r'\n\n=== \1 ===\n\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{2}\s+(.+)$', r'\n\n--- \1 ---\n\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{3,6}\s+(.+)$', r'\n\nâ–¶ \1\n\n', text, flags=re.MULTILINE)
        
        # å¤„ç†ç²—ä½“å’Œæ–œä½“
        text = re.sub(r'\*\*(.+?)\*\*', r'ã€\1ã€‘', text)
        text = re.sub(r'\*(.+?)\*', r'ã€Š\1ã€‹', text)
        
        # å¤„ç†ä»£ç 
        text = re.sub(r'`(.+?)`', r'ã€Œ\1ã€', text)
        text = re.sub(r'```[\w]*\n(.*?)\n```', r'\n\nâ”Œâ”€ ä»£ç ç¤ºä¾‹ â”€â”\n\1\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n', text, flags=re.DOTALL)
        
        # å¤„ç†å¼•ç”¨
        text = re.sub(r'^>\s*(.+)$', r'â”ƒ \1', text, flags=re.MULTILINE)
        
        # å¤„ç†åˆ—è¡¨
        text = re.sub(r'^[-*+]\s+(.+)$', r'- \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\d+\.\s+(.+)$', r'â€¢ \1', text, flags=re.MULTILINE)
        
        # å¤„ç†é“¾æ¥
        text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'\1ï¼ˆ\2ï¼‰', text)
        
        # å¤„ç†åˆ†éš”çº¿
        text = re.sub(r'^---+$', 'â”€' * 50, text, flags=re.MULTILINE)
        
        # æ¸…ç†å¤šä½™ç©ºè¡Œ
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        return text.strip()
    
    def _clean_text(self, text):
        """æ¸…ç†æ–‡æœ¬å†…å®¹"""
        if not text:
            return ""
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)  # å¤šä¸ªæ¢è¡Œå˜ä¸ºä¸¤ä¸ª
        text = re.sub(r'[ \t]+', ' ', text)  # å¤šä¸ªç©ºæ ¼å˜ä¸ºä¸€ä¸ª
        text = re.sub(r'^\s+|\s+$', '', text, flags=re.MULTILINE)  # å»é™¤è¡Œé¦–è¡Œå°¾ç©ºæ ¼
        
        # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'[\u200b\u200c\u200d\ufeff]', '', text)  # é›¶å®½å­—ç¬¦
        text = text.strip()
        
        return text
    
    def _remove_unwanted_elements(self, soup):
        """ç§»é™¤ä¸éœ€è¦çš„HTMLå…ƒç´ """
        # ç§»é™¤scriptã€styleã€navç­‰ä¸éœ€è¦çš„æ ‡ç­¾
        unwanted_tags = [
            'script', 'style', 'nav', 'header', 'footer', 'aside',
            'advertisement', 'ad', 'sidebar', 'menu', 'breadcrumb',
            'iframe', 'embed', 'object'
        ]
        
        for tag_name in unwanted_tags:
            for tag in soup.find_all(tag_name):
                tag.decompose()
        
        # ç§»é™¤å¸¸è§çš„å¹¿å‘Šå’Œæ— å…³å†…å®¹çš„class/id
        unwanted_patterns = [
            r'ad[_-]', r'advertisement', r'sponsor', r'promo', 
            r'sidebar', r'related', r'comment', r'footer', 
            r'header', r'nav', r'breadcrumb', r'pagination', 
            r'share', r'social', r'tracking', r'analytics'
        ]
        
        for pattern in unwanted_patterns:
            for tag in soup.find_all(class_=re.compile(pattern, re.I)):
                tag.decompose()
            for tag in soup.find_all(id=re.compile(pattern, re.I)):
                tag.decompose()
        
        return soup
    
    def _enhance_title_with_emoji(self, title):
        """ä¸ºæ ‡é¢˜æ·»åŠ åˆé€‚çš„emoji"""
        title_lower = title.lower()
        
        for keyword, emoji in self.content_enhancers['emoji_mapping'].items():
            if keyword in title_lower:
                if not title.startswith(emoji):
                    return f"{emoji} {title}"
                break
        
        return title
    
    def _detect_code_language(self, code_elem):
        """æ£€æµ‹ä»£ç è¯­è¨€"""
        # ä»classå±æ€§æ£€æµ‹
        class_attr = code_elem.get('class', [])
        if class_attr:
            for cls in class_attr:
                for lang_key, lang_name in self.content_enhancers['code_languages'].items():
                    if lang_key in cls.lower():
                        return lang_key
        
        # ä»å†…å®¹ç‰¹å¾æ£€æµ‹
        code_text = code_elem.get_text()[:200].lower()
        
        language_patterns = {
            'javascript': [r'function\s*\(', r'const\s+\w+', r'let\s+\w+', r'console\.log'],
            'python': [r'def\s+\w+\(', r'import\s+\w+', r'from\s+\w+\s+import', r'print\('],
            'java': [r'public\s+class', r'public\s+static\s+void', r'System\.out\.println'],
            'css': [r'\.\w+\s*{', r'#\w+\s*{', r'@media', r'flex'],
            'html': [r'<html', r'<div', r'<span', r'<!DOCTYPE'],
            'json': [r'^\s*[{\[]', r'"\w+":', r'},\s*"'],
            'sql': [r'SELECT\s+', r'FROM\s+', r'WHERE\s+', r'INSERT\s+INTO']
        }
        
        for lang, patterns in language_patterns.items():
            if any(re.search(pattern, code_text, re.I) for pattern in patterns):
                return lang
        
        return ''
    
    def _format_code_block(self, code_elem):
        """æ ¼å¼åŒ–ä»£ç å—"""
        code_text = code_elem.get_text()
        
        # æ£€æµ‹è¯­è¨€
        language = self._detect_code_language(code_elem)
        lang_display = self.content_enhancers.get('code_languages', {}).get(language, language)
        
        # æ¸…ç†ä»£ç æ–‡æœ¬
        code_text = code_text.strip()
        
        # æ·»åŠ è¯­è¨€æ ‡æ³¨
        if lang_display:
            return f"\n\nğŸ’» **{lang_display} ä»£ç ç¤ºä¾‹ï¼š**\n\n```{language}\n{code_text}\n```\n\n"
        else:
            return f"\n\n```\n{code_text}\n```\n\n"
    
    def _format_list_item(self, li_elem, list_type='ul', index=1):
        """æ ¼å¼åŒ–åˆ—è¡¨é¡¹"""
        text = li_elem.get_text().strip()
        
        if list_type == 'ol':
            prefix = f"{index}."
        else:
            # æ ¹æ®å†…å®¹é€‰æ‹©ä¸åŒçš„å‰ç¼€
            if any(keyword in text.lower() for keyword in ['ä¼˜ç‚¹', 'å¥½å¤„', 'ä¼˜åŠ¿']):
                prefix = "âœ…"
            elif any(keyword in text.lower() for keyword in ['ç¼ºç‚¹', 'é—®é¢˜', 'ä¸è¶³']):
                prefix = "âŒ"
            elif any(keyword in text.lower() for keyword in ['æ³¨æ„', 'è­¦å‘Š', 'å°å¿ƒ']):
                prefix = "âš ï¸"
            elif any(keyword in text.lower() for keyword in ['é‡è¦', 'å…³é”®', 'æ ¸å¿ƒ']):
                prefix = "ğŸ”‘"
            else:
                prefix = "â€¢"
        
        return f"{prefix} {text}"
    
    def _extract_juejin(self, soup, url):
        """æå–æ˜é‡‘æ–‡ç« å†…å®¹"""
        # ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ 
        soup = self._remove_unwanted_elements(soup)
        
        # æå–æ ‡é¢˜
        title_selectors = [
            'h1.article-title',
            '.article-title', 
            'h1',
            '[data-page-title]'
        ]
        
        title = "æœªçŸ¥æ ‡é¢˜"
        for selector in title_selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                title = title_elem.get_text().strip()
                break
        
        # æŸ¥æ‰¾æ–‡ç« å†…å®¹å®¹å™¨
        content_selectors = [
            '.markdown-body',
            '.article-content', 
            '[data-v-md-line]',
            '.content',
            'article',
            '.post-content'
        ]
        
        content_elem = None
        for selector in content_selectors:
            content_elem = soup.select_one(selector)
            if content_elem:
                break
        
        if not content_elem:
            # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šå®¹å™¨ï¼Œå°è¯•æ‰¾ä¸»è¦å†…å®¹åŒºåŸŸ
            main_content = soup.find('main') or soup.find('div', class_=re.compile(r'content|article|post'))
            if main_content:
                content_elem = main_content
        
        content = ""
        if content_elem:
            # ä½¿ç”¨æ–°çš„æ ¼å¼åŒ–å™¨è½¬æ¢HTMLä¸ºæ–‡æœ¬
            content = self.formatter.html_to_text(str(content_elem))
        
        # æå–æ ‡ç­¾
        tags = self._extract_tags_juejin(soup)
        
        return title, content, tags
    
    def _extract_cnblogs(self, soup, url):
        """æå–åšå®¢å›­æ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='postTitle') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', id='cnblogs_post_body') or soup.find('div', class_='postBody')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        tags = ['æŠ€æœ¯åˆ†äº«', 'åšå®¢å›­']
        return title, content, tags
    
    def _extract_csdn(self, soup, url):
        """æå–CSDNæ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='title-article') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', id='content_views') or soup.find('div', class_='markdown_views')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        # æå–CSDNæ ‡ç­¾
        tag_elems = soup.find_all('a', class_='tag-link')
        tags = [tag.get_text().strip() for tag in tag_elems[:5]] if tag_elems else ['æŠ€æœ¯åˆ†äº«', 'CSDN']
        
        return title, content, tags
    
    def _extract_jianshu(self, soup, url):
        """æå–ç®€ä¹¦æ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='title') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', class_='show-content') or soup.find('article')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        tags = ['æŠ€æœ¯åˆ†äº«', 'ç®€ä¹¦']
        return title, content, tags
    
    def _extract_zhihu(self, soup, url):
        """æå–çŸ¥ä¹æ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='Post-Title') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', class_='RichText') or soup.find('div', class_='Post-RichTextContainer')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        # æå–çŸ¥ä¹è¯é¢˜æ ‡ç­¾
        topic_elems = soup.find_all('a', class_='TopicLink')
        tags = [topic.get_text().strip() for topic in topic_elems[:5]] if topic_elems else ['çŸ¥è¯†åˆ†äº«', 'çŸ¥ä¹']
        
        return title, content, tags
    
    def _extract_segmentfault(self, soup, url):
        """æå–SegmentFaultæ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='article__title') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', class_='article__content') or soup.find('div', class_='markdown-body')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        # æå–æ ‡ç­¾
        tag_elems = soup.find_all('a', class_='article-tag')
        tags = [tag.get_text().strip() for tag in tag_elems[:5]] if tag_elems else ['æŠ€æœ¯åˆ†äº«', 'SegmentFault']
        
        return title, content, tags
    
    def _extract_oschina(self, soup, url):
        """æå–å¼€æºä¸­å›½æ–‡ç« å†…å®¹"""
        soup = self._remove_unwanted_elements(soup)
        
        title_elem = soup.find('h1', class_='article-box__title') or soup.find('h1')
        title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
        
        content_elem = soup.find('div', class_='article-detail') or soup.find('div', class_='content')
        content = self._html_to_markdown_enhanced(content_elem) if content_elem else ""
        
        tags = ['æŠ€æœ¯åˆ†äº«', 'å¼€æºä¸­å›½']
        return title, content, tags
    
    def _extract_tags_juejin(self, soup):
        """æå–æ˜é‡‘æ–‡ç« æ ‡ç­¾"""
        tag_selectors = [
            '.tag-list .tag',
            '.article-tag',
            '.tag',
            '[data-tag]'
        ]
        
        tags = []
        for selector in tag_selectors:
            tag_elems = soup.select(selector)
            if tag_elems:
                tags = [tag.get_text().strip() for tag in tag_elems[:6] if tag.get_text().strip()]
                break
        
        if not tags:
            tags = ['æŠ€æœ¯åˆ†äº«', 'æ˜é‡‘']
        
        return tags
    
    def _html_to_markdown_enhanced(self, element):
        """å¢å¼ºç‰ˆHTMLåˆ°Markdownè½¬æ¢"""
        if not element:
            return ""
        
        def process_element(elem, depth=0):
            """é€’å½’å¤„ç†HTMLå…ƒç´ """
            if isinstance(elem, NavigableString):
                text = str(elem).strip()
                return text if text else ""
            
            if not isinstance(elem, Tag):
                return ""
            
            tag_name = elem.name.lower()
            
            # è·³è¿‡ä¸éœ€è¦çš„æ ‡ç­¾
            if tag_name in ['script', 'style', 'meta', 'link', 'head']:
                return ""
            
            # è·å–å­å…ƒç´ å†…å®¹
            children_content = []
            for child in elem.children:
                child_result = process_element(child, depth + 1)
                if child_result:
                    children_content.append(child_result)
            
            text_content = ' '.join(children_content) if children_content else elem.get_text().strip()
            
            # æ ¹æ®æ ‡ç­¾ç±»å‹è¿›è¡Œè½¬æ¢
            if tag_name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                level = int(tag_name[1])
                if text_content:
                    # ä¸ºæ ‡é¢˜æ·»åŠ emoji
                    enhanced_title = self._enhance_title_with_emoji(text_content)
                    return f"\n\n{'#' * level} {enhanced_title}\n\n"
            
            elif tag_name == 'p':
                if text_content:
                    return f"\n\n{text_content}\n\n"
            
            elif tag_name in ['strong', 'b']:
                if text_content:
                    return f"**{text_content}**"
            
            elif tag_name in ['em', 'i']:
                if text_content:
                    return f"*{text_content}*"
            
            elif tag_name == 'code' and elem.parent.name != 'pre':
                if text_content:
                    return f"`{text_content}`"
            
            elif tag_name == 'pre':
                # å¤„ç†ä»£ç å—
                code_elem = elem.find('code')
                if code_elem:
                    return self._format_code_block(code_elem)
                else:
                    return f"\n\n```\n{text_content}\n```\n\n"
            
            elif tag_name in ['ul', 'ol']:
                # å¤„ç†åˆ—è¡¨
                list_items = []
                for i, li in enumerate(elem.find_all('li', recursive=False), 1):
                    li_content = process_element(li, depth + 1)
                    if li_content:
                        formatted_item = self._format_list_item(li, tag_name, i)
                        list_items.append(formatted_item)
                
                if list_items:
                    return f"\n\n" + "\n".join(list_items) + "\n\n"
            
            elif tag_name == 'li':
                return text_content
            
            elif tag_name == 'blockquote':
                if text_content:
                    # å¤„ç†å¼•ç”¨å—
                    quoted_lines = text_content.split('\n')
                    quoted_text = '\n'.join(f"> ğŸ’¡ {line.strip()}" for line in quoted_lines if line.strip())
                    return f"\n\n{quoted_text}\n\n"
            
            elif tag_name == 'a':
                href = element.get('href', '')
                if text_content and href:
                    return f"[{text_content}]({href})"
                else:
                    return text_content
            
            elif tag_name == 'img':
                alt = element.get('alt', 'å›¾ç‰‡')
                src = element.get('src', '')
                if src:
                    return f"\n\n![{alt}]({src})\n\n"
            
            elif tag_name in ['table']:
                return f"\n\nğŸ“Š **æ•°æ®è¡¨æ ¼**\n\n{text_content}\n\n"
            
            elif tag_name in ['br']:
                return "\n"
            
            elif tag_name in ['hr']:
                return f"\n\n---\n\n"
            
            elif tag_name in ['div', 'section', 'article']:
                # å¯¹äºå®¹å™¨å…ƒç´ ï¼Œè¿”å›å­å…ƒç´ å†…å®¹
                if children_content:
                    return ' '.join(children_content)
                else:
                    return text_content
            
            else:
                return text_content
        
        # å¤„ç†æ•´ä¸ªå…ƒç´ 
        result = process_element(element)
        
        # æ¸…ç†å’Œæ ¼å¼åŒ–ç»“æœ
        if result:
            result = self._clean_text(result)
            # ç¡®ä¿æ®µè½ä¹‹é—´æœ‰é€‚å½“çš„åˆ†éš”
            result = re.sub(r'\n{3,}', '\n\n', result)
            # æ¸…ç†åˆ—è¡¨æ ¼å¼
            result = re.sub(r'\n+(â€¢|âœ…|âŒ|âš ï¸|ğŸ”‘|\d+\.)\s+', r'\n\1 ', result)
            
        return result
    
    def _extract_generic(self, soup, url):
        """é€šç”¨æ–‡ç« å†…å®¹æå–"""
        soup = self._remove_unwanted_elements(soup)
        
        # å°è¯•å¤šç§æ ‡é¢˜é€‰æ‹©å™¨
        title_selectors = ['h1', '.title', '.article-title', '.post-title', '[data-title]']
        title = "æœªçŸ¥æ ‡é¢˜"
        
        for selector in title_selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                title = title_elem.get_text().strip()
                break
        
        # å°è¯•å¤šç§å†…å®¹é€‰æ‹©å™¨
        content_selectors = [
            'article', '.content', '.article-content', '.post-content',
            '.markdown-body', '.article-body', '.entry-content',
            'main', '.main-content', '.post-body'
        ]
        content = ""
        
        for selector in content_selectors:
            content_elem = soup.select_one(selector)
            if content_elem:
                content = self._html_to_markdown_enhanced(content_elem)
                if len(content) > 100:  # ç¡®ä¿è·å–åˆ°è¶³å¤Ÿçš„å†…å®¹
                    break
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°å†…å®¹ï¼Œå°è¯•æ™ºèƒ½æå–
        if not content or len(content) < 100:
            content = self._smart_content_extraction(soup)
        
        tags = ['æ–‡ç« è½¬å‘', 'æŠ€æœ¯åˆ†äº«']
        return title, content, tags
    
    def _smart_content_extraction(self, soup):
        """æ™ºèƒ½å†…å®¹æå–ç®—æ³•"""
        # æ‰¾åˆ°æ‰€æœ‰å¯èƒ½åŒ…å«å†…å®¹çš„div
        content_divs = soup.find_all('div')
        
        best_content = ""
        max_text_length = 0
        
        for div in content_divs:
            # è·³è¿‡æ˜æ˜¾çš„å¯¼èˆªã€å¹¿å‘Šç­‰åŒºåŸŸ
            div_class = ' '.join(div.get('class', [])).lower()
            div_id = (div.get('id') or '').lower()
            
            skip_patterns = ['nav', 'menu', 'sidebar', 'footer', 'header', 'ad', 'comment']
            if any(pattern in div_class or pattern in div_id for pattern in skip_patterns):
                continue
            
            div_text = div.get_text().strip()
            
            # é€‰æ‹©æ–‡æœ¬æœ€é•¿çš„divä½œä¸ºä¸»è¦å†…å®¹
            if len(div_text) > max_text_length:
                max_text_length = len(div_text)
                best_content = self._html_to_markdown_enhanced(div)
        
        return best_content
    
    async def fetch_article(self, url):
        """è·å–æ–‡ç« å†…å®¹"""
        print(f"ğŸŒ æ­£åœ¨è·å–æ–‡ç« : {url}")
        
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºçŸ¥ä¹é“¾æ¥
            if 'zhihu.com' in url:
                return await self._fetch_zhihu_article(url)
            
            # å‘é€HTTPè¯·æ±‚
            response = requests.get(url, headers=self.headers, timeout=30)
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None, None, None
            
            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æ ¹æ®ç½‘ç«™ç±»å‹é€‰æ‹©æå–å™¨
            domain = urlparse(url).netloc.lower()
            extractor = None
            
            for site, extract_func in self.site_configs.items():
                if site in domain:
                    extractor = extract_func
                    break
            
            if not extractor:
                extractor = self._extract_generic
            
            title, content, tags = extractor(soup, url)
            
            print(f"âœ… æ–‡ç« è·å–æˆåŠŸ: æ ‡é¢˜={title}, æ ‡ç­¾={tags}, å†…å®¹é•¿åº¦={len(content) if content else 0}")
            print(f"ğŸ“ æ ‡é¢˜: {title}")
            print(f"ğŸ“Š å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            print(f"ğŸ·ï¸ æ ‡ç­¾: {tags}")
            
            return title, content, tags
            
        except Exception as e:
            print(f"âŒ è·å–æ–‡ç« å¤±è´¥: {e}")
            return None, None, None
            
    async def _fetch_zhihu_article(self, url):
        """ä½¿ç”¨Playwrightæ¨¡æ‹Ÿæµè§ˆå™¨è·å–çŸ¥ä¹æ–‡ç« å†…å®¹"""
        print("ğŸ” æ£€æµ‹åˆ°çŸ¥ä¹é“¾æ¥ï¼Œä½¿ç”¨æµè§ˆå™¨æ¨¡æ‹Ÿè®¿é—®...")
        
        try:
            # ä»URLä¸­æå–æ–‡ç« ID
            article_id = url.split('/')[-1]
            print(f"ğŸ“ çŸ¥ä¹æ–‡ç« ID: {article_id}")
            
            # ä½¿ç”¨Playwrightæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
            async with async_playwright() as playwright:
                # ä½¿ç”¨æœ‰ç•Œé¢æ¨¡å¼ä»¥ä¾¿è§‚å¯Ÿ
                browser = await playwright.chromium.launch(headless=False)
                
                # åˆ›å»ºä¸Šä¸‹æ–‡å¹¶æ·»åŠ åçˆ¬è™«æªæ–½
                context = await browser.new_context(
                    user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                    viewport={"width": 1280, "height": 800},
                    device_scale_factor=1,
                )
                
                # æ·»åŠ stealth.jsè„šæœ¬æ¥ç»•è¿‡åçˆ¬è™«æ£€æµ‹
                stealth_js_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "utils/stealth.min.js")
                if os.path.exists(stealth_js_path):
                    with open(stealth_js_path, "r") as f:
                        stealth_js = f.read()
                    await context.add_init_script(stealth_js)
                
                # åˆ›å»ºé¡µé¢
                page = await context.new_page()
                
                # è®¾ç½®è¶…æ—¶
                page.set_default_timeout(60000)  # 60ç§’è¶…æ—¶
                
                # è®¿é—®çŸ¥ä¹æ–‡ç« é¡µé¢
                print(f"ğŸŒ æ­£åœ¨è®¿é—®çŸ¥ä¹æ–‡ç« : {url}")
                await page.goto(url)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰éªŒè¯ç æˆ–ç™»å½•å¼¹çª—
                print("â³ ç­‰å¾…é¡µé¢åŠ è½½ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰éªŒè¯ç ...")
                await page.wait_for_load_state("networkidle")
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œè®©é¡µé¢å®Œå…¨åŠ è½½
                await page.wait_for_timeout(5000)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†éªŒè¯ç 
                if await page.query_selector('.Captcha') or await page.query_selector('.SignFlowInput'):
                    print("âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç æˆ–ç™»å½•å¼¹çª—ï¼Œéœ€è¦äººå·¥å¤„ç†")
                    print("è¯·åœ¨æ‰“å¼€çš„æµè§ˆå™¨ä¸­å®ŒæˆéªŒè¯ï¼Œç„¶åè„šæœ¬å°†ç»§ç»­...")
                    
                    # ç­‰å¾…ç”¨æˆ·å¤„ç†éªŒè¯ç 
                    await page.wait_for_selector('.Post-Title, .QuestionHeader-title, .ArticleHeader-title', timeout=120000)
                
                # å†æ¬¡ç­‰å¾…é¡µé¢åŠ è½½
                await page.wait_for_load_state("networkidle")
                await page.wait_for_timeout(2000)
                
                # æˆªå›¾ç”¨äºè°ƒè¯•
                screenshot_path = "zhihu_debug.png"
                await page.screenshot(path=screenshot_path)
                print(f"ğŸ“¸ é¡µé¢æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
                
                # å°è¯•è·å–æ ‡é¢˜
                title_selectors = [
                    '.Post-Title', 
                    '.QuestionHeader-title', 
                    '.ArticleHeader-title',
                    'h1'
                ]
                
                title = "æœªçŸ¥æ ‡é¢˜"
                for selector in title_selectors:
                    title_element = await page.query_selector(selector)
                    if title_element:
                        title = await title_element.text_content()
                        title = title.strip()
                        if title:
                            break
                
                # å°è¯•è·å–å†…å®¹
                content_selectors = [
                    '.Post-RichTextContainer', 
                    '.QuestionRichText',
                    '.RichText',
                    '.Post-RichText',
                    'article'
                ]
                
                content_html = ""
                for selector in content_selectors:
                    try:
                        content_html = await page.evaluate(f"""() => {{
                            const element = document.querySelector('{selector}');
                            return element ? element.innerHTML : '';
                        }}""")
                        
                        if content_html:
                            break
                    except Exception as e:
                        print(f"å°è¯•é€‰æ‹©å™¨ {selector} å¤±è´¥: {e}")
                
                if not content_html:
                    # å¦‚æœæ‰€æœ‰é€‰æ‹©å™¨éƒ½å¤±è´¥ï¼Œå°è¯•è·å–æ•´ä¸ªé¡µé¢å†…å®¹
                    content_html = await page.content()
                
                # ä½¿ç”¨BeautifulSoupè§£æHTML
                soup = BeautifulSoup(content_html, 'html.parser')
                
                # ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ 
                for unwanted in soup.select('.CommentBox, .Reward, .FollowButton, .VoteButton, .ContentItem-actions'):
                    if unwanted:
                        unwanted.decompose()
                
                # è½¬æ¢ä¸ºMarkdown
                content = self._html_to_markdown_enhanced(soup)
                
                # æå–æ ‡ç­¾
                tags = []
                tag_selectors = ['.Tag-content .Tag-label', '.TopicLink', '.Tag']
                
                for selector in tag_selectors:
                    tag_elements = await page.query_selector_all(selector)
                    for tag_element in tag_elements:
                        tag_text = await tag_element.text_content()
                        if tag_text and tag_text.strip():
                            tags.append(tag_text.strip())
                    
                    if tags:
                        break
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾
                if not tags:
                    tags = ['çŸ¥ä¹', 'æ–‡ç« è½¬å‘']
                
                # å…³é—­æµè§ˆå™¨
                await browser.close()
                
                # æ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                if len(content) < 100:
                    print(f"âš ï¸ è·å–çš„å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½æœªæˆåŠŸæŠ“å–: {len(content)} å­—ç¬¦")
                    return None, None, None
                
                print(f"âœ… çŸ¥ä¹æ–‡ç« è·å–æˆåŠŸ:")
                print(f"ğŸ“ æ ‡é¢˜: {title}")
                print(f"ğŸ“Š å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                print(f"ğŸ·ï¸ æ ‡ç­¾: {tags}")
                
                return title, content, tags
                
        except Exception as e:
            print(f"âŒ çŸ¥ä¹æ–‡ç« è·å–å¤±è´¥: {e}")
            traceback.print_exc()  # æ‰“å°å®Œæ•´é”™è¯¯å †æ ˆï¼Œä¾¿äºè°ƒè¯•
            return None, None, None
    
    def _enhance_content_format(self, title, content, url, use_rich_text=True):
        """å¢å¼ºå†…å®¹æ ¼å¼åŒ– - V3ç‰ˆæœ¬"""
        if not content:
            return ""
        
        # ç§»é™¤åŸæ–‡é“¾æ¥å’Œè½¬å‘æ—¶é—´ä¿¡æ¯ï¼Œä»Šæ—¥å¤´æ¡ä¸éœ€è¦è¿™äº›
        # source_info = f"""
        # > **åŸæ–‡é“¾æ¥**: {url}
        # > **è½¬å‘æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}
        # > **å†…å®¹ä¼˜åŒ–**: å·²ä¼˜åŒ–æ’ç‰ˆæ ¼å¼ï¼Œæå‡é˜…è¯»ä½“éªŒ

        # ---

        # """
        
        # å¤„ç†æ­£æ–‡å†…å®¹
        content = content.strip()
        
        # 1. ä¸å†æ·»åŠ æ ‡é¢˜åˆ°å†…å®¹ä¸­ï¼Œå› ä¸ºä»Šæ—¥å¤´æ¡å·²ç»æœ‰å•ç‹¬çš„æ ‡é¢˜å­—æ®µ
        # if title and not content.startswith('# '):
        #     content = f"# {title}\n\n{content}"
        
        # 2. ä¼˜åŒ–æ®µè½æ ¼å¼
        paragraphs = content.split('\n\n')
        formatted_paragraphs = []
        
        for para in paragraphs:
            para = para.strip()
            if not para:
                continue
                
            # å¤„ç†æ ‡é¢˜ - ç¡®ä¿markdownæ ‡é¢˜æ­£ç¡®è½¬æ¢
            if re.match(r'^#{1,6}\s+', para):
                # ç¡®ä¿æ ‡é¢˜æ ¼å¼æ­£ç¡®ï¼Œä¾‹å¦‚ "## æ ‡é¢˜" è€Œä¸æ˜¯ "#ï¼ƒ æ ‡é¢˜"
                para = re.sub(r'^(#{1,6})\s*', r'\1 ', para)
                formatted_paragraphs.append(f"\n{para}\n")
                continue
            
            # å¤„ç†å¯èƒ½è¢«é”™è¯¯æ ¼å¼åŒ–çš„æ ‡é¢˜ï¼ˆä¾‹å¦‚ "##å‰è¨€" æ²¡æœ‰ç©ºæ ¼ï¼‰
            if re.match(r'^#{1,6}[^#\s]', para):
                para = re.sub(r'^(#{1,6})([^#\s])', r'\1 \2', para)
                formatted_paragraphs.append(f"\n{para}\n")
                continue
            
            # å¤„ç†ä»£ç å—
            if para.startswith('```'):
                formatted_paragraphs.append(para)
                continue
            
            # å¤„ç†å¼•ç”¨å—
            if para.startswith('>'):
                lines = para.split('\n')
                formatted_lines = []
                for line in lines:
                    if line.startswith('>'):
                        formatted_lines.append(line)
                    else:
                        formatted_lines.append(f"> {line}")
                formatted_paragraphs.append('\n'.join(formatted_lines))
                continue
            
            # å¤„ç†åˆ—è¡¨
            if re.match(r'^[-*+]\s|^\d+\.\s', para):
                lines = para.split('\n')
                # ä¿æŒåˆ—è¡¨é¡¹çš„åŸå§‹ç¼©è¿›
                formatted_paragraphs.append('\n'.join(lines))
                continue
            
            # å¤„ç†æ™®é€šæ®µè½
            # å°†æ®µè½å†…çš„å¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ª
            para = re.sub(r'\s+', ' ', para)
            # ç¡®ä¿ä¸­æ–‡å’Œè‹±æ–‡ä¹‹é—´æœ‰ç©ºæ ¼
            para = re.sub(r'([a-zA-Z])([\u4e00-\u9fff])', r'\1 \2', para)
            para = re.sub(r'([\u4e00-\u9fff])([a-zA-Z])', r'\1 \2', para)
            # ä¿®å¤ä¸­æ–‡æ ‡ç‚¹åé¢çš„ç©ºæ ¼
            para = re.sub(r'([ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€])\s+', r'\1', para)
            
            formatted_paragraphs.append(para)
        
        # 3. åˆå¹¶å¤„ç†åçš„å†…å®¹
        content = '\n\n'.join(formatted_paragraphs)
        
        # 4. ä¸å†æ·»åŠ æ–‡ç« æ¥æºä¿¡æ¯
        # content = source_info + content
        
        # 5. æœ€ç»ˆçš„æ ¼å¼æ¸…ç†
        content = re.sub(r'\n{3,}', '\n\n', content)  # åˆ é™¤å¤šä½™çš„ç©ºè¡Œ
        content = re.sub(r'[ \t]+\n', '\n', content)  # åˆ é™¤è¡Œå°¾ç©ºæ ¼
        content = content.strip()
        
        if use_rich_text:
            print("ğŸ¨ æ­£åœ¨å°†Markdownè½¬æ¢ä¸ºå¯Œæ–‡æœ¬æ ¼å¼...")
            
            # ä½¿ç”¨ markdown åº“å°† Markdown è½¬æ¢ä¸º HTML
            import markdown
            html_content = markdown.markdown(
                content,
                extensions=[
                    'markdown.extensions.extra',
                    'markdown.extensions.codehilite',
                    'markdown.extensions.tables',
                    'markdown.extensions.nl2br'
                ]
            )
            
            # æ·»åŠ åŸºæœ¬æ ·å¼
            html_content = f"""
            <div style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif; line-height: 1.6; color: #333;">
                {html_content}
            </div>
            """
            
            # ä½¿ç”¨ä»Šæ—¥å¤´æ¡å¯Œæ–‡æœ¬ç¼–è¾‘å™¨æ”¯æŒçš„æ ¼å¼
            # æ›¿æ¢æ ‡é¢˜æ ·å¼
            html_content = re.sub(r'<h1>(.*?)</h1>', r'<h1 style="font-size: 24px; font-weight: bold; margin: 20px 0 10px;">\1</h1>', html_content)
            html_content = re.sub(r'<h2>(.*?)</h2>', r'<h2 style="font-size: 20px; font-weight: bold; margin: 18px 0 9px;">\1</h2>', html_content)
            html_content = re.sub(r'<h3>(.*?)</h3>', r'<h3 style="font-size: 18px; font-weight: bold; margin: 16px 0 8px;">\1</h3>', html_content)
            
            # æ›¿æ¢ä»£ç å—æ ·å¼
            html_content = re.sub(
                r'<pre><code>(.*?)</code></pre>',
                r'<pre style="background-color: #f6f8fa; border-radius: 3px; padding: 10px; overflow: auto;"><code>\1</code></pre>',
                html_content,
                flags=re.DOTALL
            )
            
            # æ›¿æ¢è¡Œå†…ä»£ç æ ·å¼
            html_content = re.sub(
                r'<code>(.*?)</code>',
                r'<code style="background-color: #f6f8fa; border-radius: 3px; padding: 2px 4px; font-family: monospace;">\1</code>',
                html_content
            )
            
            # æ›¿æ¢å¼•ç”¨å—æ ·å¼
            html_content = re.sub(
                r'<blockquote>(.*?)</blockquote>',
                r'<blockquote style="border-left: 4px solid #ddd; padding-left: 10px; margin-left: 0; color: #666;">\1</blockquote>',
                html_content,
                flags=re.DOTALL
            )
            
            # æ›¿æ¢åˆ—è¡¨æ ·å¼
            html_content = re.sub(r'<ul>', r'<ul style="padding-left: 20px;">', html_content)
            html_content = re.sub(r'<ol>', r'<ol style="padding-left: 20px;">', html_content)
            
            print(f"âœ… HTMLæ ¼å¼åŒ–å®Œæˆï¼Œæœ€ç»ˆé•¿åº¦: {len(html_content)} å­—ç¬¦")
            print("ğŸ“ æ ¼å¼åŒ–ç‰¹æ€§: HTMLå¯Œæ–‡æœ¬ã€ç¾åŒ–æ ‡é¢˜ã€ä»£ç é«˜äº®ã€é€‚å½“æ®µè½é—´è·")
            
            return html_content
        else:
            # è¿”å› Markdown æ ¼å¼ï¼ˆç”¨äºä¿å­˜æ–‡ä»¶ï¼‰
            return content
    
    def _optimize_content_spacing(self, content):
        """ä¼˜åŒ–å†…å®¹é—´è· - V2ç‰ˆæœ¬"""
        if not content:
            return ""
        
        # 1. æ ‡å‡†åŒ–æ¢è¡Œç¬¦
        content = content.replace('\r\n', '\n').replace('\r', '\n')
        
        # 2. å¤„ç†æ ‡é¢˜é—´è·
        content = re.sub(r'\n(#{1,6}\s+[^\n]+)\n', r'\n\n\1\n\n', content)
        
        # 3. å¤„ç†ä»£ç å—é—´è·
        content = re.sub(r'\n```([^\n]*)\n', r'\n\n```\1\n', content)
        content = re.sub(r'\n```\n', r'\n```\n\n', content)
        
        # 4. å¤„ç†åˆ—è¡¨æ ¼å¼
        def format_list(match):
            list_content = match.group(0)
            lines = list_content.split('\n')
            # ä¿æŒåˆ—è¡¨é¡¹ä¹‹é—´çš„ç´§å‡‘æ€§ï¼Œä½†åœ¨åˆ—è¡¨å‰åæ·»åŠ ç©ºè¡Œ
            return f"\n\n{list_content}\n\n"
        
        content = re.sub(r'((?:^[-*+]\s+[^\n]+\n?)+)', format_list, content, flags=re.MULTILINE)
        content = re.sub(r'((?:^\d+\.\s+[^\n]+\n?)+)', format_list, content, flags=re.MULTILINE)
        
        # 5. å¤„ç†å¼•ç”¨å—æ ¼å¼
        def format_quote(match):
            quote_content = match.group(0)
            lines = quote_content.split('\n')
            formatted_lines = []
            for line in lines:
                if line.strip():
                    if not line.startswith('>'):
                        line = f"> {line}"
                    formatted_lines.append(line)
            return '\n\n' + '\n'.join(formatted_lines) + '\n\n'
        
        content = re.sub(r'((?:^>\s+[^\n]+\n?)+)', format_quote, content, flags=re.MULTILINE)
        
        # 6. ä¼˜åŒ–æ®µè½é—´è·
        paragraphs = content.split('\n\n')
        formatted_paragraphs = []
        
        for para in paragraphs:
            para = para.strip()
            if para:
                # å¤„ç†æ®µè½å†…çš„æ¢è¡Œ
                lines = para.split('\n')
                # å¦‚æœæ˜¯æ™®é€šæ®µè½ä¸”è¡Œæ•°å¤§äº1ï¼Œè¿›è¡Œç‰¹æ®Šå¤„ç†
                if len(lines) > 1 and not any(line.startswith(('#', '>', '-', '*', '+', '```', '|')) for line in lines):
                    # å°†å¤šè¡Œåˆå¹¶ä¸ºä¸€ä¸ªæ®µè½
                    para = ' '.join(line.strip() for line in lines)
                formatted_paragraphs.append(para)
        
        content = '\n\n'.join(formatted_paragraphs)
        
        # 7. æœ€ç»ˆæ¸…ç†
        content = re.sub(r'\n{3,}', '\n\n', content)  # åˆ é™¤å¤šä½™çš„ç©ºè¡Œ
        content = re.sub(r'[ \t]+\n', '\n', content)  # åˆ é™¤è¡Œå°¾ç©ºæ ¼
        
        return content.strip()
    
    def _smart_format_content(self, content):
        """æ™ºèƒ½æ ¼å¼åŒ–å†…å®¹ - V2ç‰ˆæœ¬"""
        if not content:
            return ""
        
        # 1. ä¼˜åŒ–ä»£ç å—
        content = self._fix_code_blocks(content)
        
        # 2. ä¼˜åŒ–æ®µè½
        content = self._optimize_paragraphs(content)
        
        # 3. ä¼˜åŒ–åˆ—è¡¨
        content = self._optimize_lists(content)
        
        # 4. æ·»åŠ ä¸Šä¸‹æ–‡è¡¨æƒ…ç¬¦å·
        content = self._add_contextual_emojis(content)
        
        return content
    
    def _fix_code_blocks(self, content):
        """ä¿®å¤ä»£ç å—æ ¼å¼"""
        if not content:
            return ""
        
        # ç¡®ä¿ä»£ç å—æœ‰è¯­è¨€æ ‡è¯†
        def replace_code_block(match):
            lang = match.group(1) or ''
            code = match.group(2)
            
            # æ£€æµ‹ä»£ç è¯­è¨€
            if not lang:
                # ç®€å•çš„è¯­è¨€æ£€æµ‹é€»è¾‘
                if 'function' in code or 'var' in code or 'const' in code:
                    lang = 'javascript'
                elif 'def' in code or 'import' in code:
                    lang = 'python'
                elif '<' in code and '>' in code:
                    lang = 'html'
                else:
                    lang = 'plaintext'
            
            return f"```{lang}\n{code.strip()}\n```"
        
        content = re.sub(r'```(\w*)\n(.*?)\n```', replace_code_block, content, flags=re.DOTALL)
        
        return content
    
    def _optimize_paragraphs(self, content):
        """ä¼˜åŒ–æ®µè½æ ¼å¼"""
        if not content:
            return ""
        
        # 1. å¤„ç†æ®µè½é—´è·
        paragraphs = content.split('\n\n')
        formatted_paragraphs = []
        
        for para in paragraphs:
            para = para.strip()
            if not para:
                continue
            
            # ç‰¹æ®Šå—ä¿æŒåŸæ ¼å¼
            if any(para.startswith(prefix) for prefix in ('#', '```', '>', '-', '*', '+', '|')):
                formatted_paragraphs.append(para)
                continue
            
            # æ™®é€šæ®µè½å¤„ç†
            # åˆå¹¶å¤šè¡Œ
            lines = para.split('\n')
            if len(lines) > 1:
                # å°†å¤šè¡Œåˆå¹¶ä¸ºä¸€ä¸ªæ®µè½ï¼Œé™¤éè¡Œç»“æŸæœ‰æ ‡ç‚¹
                merged_lines = []
                current_line = []
                
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    
                    if current_line and not any(line.endswith(punct) for punct in 'ã€‚ï¼ï¼Ÿï¼›ï¼šï¼Œ.!?;:,'): 
                        current_line.append(line)
                    else:
                        if current_line:
                            merged_lines.append(' '.join(current_line))
                        current_line = [line]
                
                if current_line:
                    merged_lines.append(' '.join(current_line))
                
                para = '\n'.join(merged_lines)
            
            formatted_paragraphs.append(para)
        
        return '\n\n'.join(formatted_paragraphs)
    
    def _optimize_lists(self, content):
        """ä¼˜åŒ–åˆ—è¡¨æ ¼å¼"""
        if not content:
            return ""
        
        # å¤„ç†æ— åºåˆ—è¡¨
        def format_unordered_list(match):
            items = match.group(0).split('\n')
            return '\n'.join(f"- {item.lstrip('- ').strip()}" for item in items if item.strip())
        
        content = re.sub(r'(?:^|\n)(?:[-*+]\s+[^\n]+\n?)+', format_unordered_list, content)
        
        # å¤„ç†æœ‰åºåˆ—è¡¨
        def format_ordered_list(match):
            items = match.group(0).split('\n')
            formatted_items = []
            for i, item in enumerate(items, 1):
                if item.strip():
                    item_content = re.sub(r'^\d+\.\s*', '', item).strip()
                    formatted_items.append(f"{i}. {item_content}")
            return '\n'.join(formatted_items)
        
        content = re.sub(r'(?:^|\n)(?:\d+\.\s+[^\n]+\n?)+', format_ordered_list, content)
        
        return content
    
    def _add_contextual_emojis(self, content):
        """æ·»åŠ ä¸Šä¸‹æ–‡è¡¨æƒ…ç¬¦å·"""
        if not content:
            return ""
        
        # æ ‡é¢˜è¡¨æƒ…æ˜ å°„ - æ‰©å±•ç‰ˆ
        title_emoji_map = {
            # åŸºç¡€ç« èŠ‚
            'ä»‹ç»': 'ğŸ“', 'ç®€ä»‹': 'ğŸ“', 'å‰è¨€': 'ğŸ“', 'æ¦‚è¿°': 'ğŸ“',
            'èƒŒæ™¯': 'ğŸ”', 'ç›®æ ‡': 'ğŸ¯', 'åŠ¨æœº': 'ğŸ’¡', 'åŸç†': 'ğŸ”¬',
            
            # æŠ€æœ¯ç›¸å…³
            'å®‰è£…': 'âš™ï¸', 'é…ç½®': 'âš™ï¸', 'è®¾ç½®': 'âš™ï¸', 'ç¯å¢ƒ': 'âš™ï¸',
            'ä½¿ç”¨': 'ğŸ”¨', 'ç”¨æ³•': 'ğŸ”¨', 'å®è·µ': 'ğŸ”¨', 'æ“ä½œ': 'ğŸ”¨',
            'ç¤ºä¾‹': 'ğŸ’¡', 'ä¾‹å­': 'ğŸ’¡', 'æ¡ˆä¾‹': 'ğŸ’¡', 'æ¼”ç¤º': 'ğŸ’¡',
            'ä»£ç ': 'ğŸ’»', 'å®ç°': 'ğŸ’»', 'ç¼–ç ': 'ğŸ’»', 'ç¨‹åº': 'ğŸ’»',
            'æ¶æ„': 'ğŸ—ï¸', 'è®¾è®¡': 'ğŸ“', 'æ¨¡å¼': 'ğŸ§©', 'ç»“æ„': 'ğŸ”§',
            'æµ‹è¯•': 'ğŸ§ª', 'è°ƒè¯•': 'ğŸ”', 'ä¼˜åŒ–': 'âš¡', 'æ€§èƒ½': 'âš¡',
            
            # æç¤ºå’Œè­¦å‘Š
            'æ³¨æ„': 'âš ï¸', 'è­¦å‘Š': 'âš ï¸', 'æç¤º': 'ğŸ’¡', 'å»ºè®®': 'ğŸ’¡',
            'é—®é¢˜': 'â“', 'è§£å†³': 'âœ…', 'é”™è¯¯': 'âŒ', 'å¼‚å¸¸': 'âš ï¸',
            'å¸¸è§é—®é¢˜': 'â“', 'FAQ': 'â“', 'ç–‘éš¾è§£ç­”': 'ğŸ”§',
            
            # æ€»ç»“ç±»
            'æ€»ç»“': 'ğŸ“Œ', 'ç»“è®º': 'ğŸ“Œ', 'å°ç»“': 'ğŸ“Œ', 'å›é¡¾': 'ğŸ“Œ',
            'å±•æœ›': 'ğŸ”­', 'æœªæ¥': 'ğŸ”®', 'è®¡åˆ’': 'ğŸ“…', 'è·¯çº¿å›¾': 'ğŸ—ºï¸',
            
            # åŠŸèƒ½å’Œç‰¹æ€§
            'ç‰¹æ€§': 'âœ¨', 'åŠŸèƒ½': 'âœ¨', 'ç‰¹ç‚¹': 'âœ¨', 'äº®ç‚¹': 'âœ¨',
            'ä¼˜ç‚¹': 'ğŸ‘', 'ç¼ºç‚¹': 'ğŸ‘', 'ä¼˜åŠ¿': 'ğŸ‘', 'åŠ£åŠ¿': 'ğŸ‘',
            
            # æµç¨‹å’Œæ­¥éª¤
            'æ­¥éª¤': 'ğŸ“‹', 'æµç¨‹': 'ğŸ“‹', 'è¿‡ç¨‹': 'ğŸ“‹', 'é˜¶æ®µ': 'ğŸ“‹',
            'æ–¹æ³•': 'ğŸ”§', 'æŠ€å·§': 'ğŸ’¡', 'ç­–ç•¥': 'ğŸ¯', 'å®æˆ˜': 'âš”ï¸',
            
            # é¢è¯•ç›¸å…³
            'é¢è¯•': 'ğŸ¯', 'é¢˜ç›®': 'ğŸ“', 'è§£ç­”': 'âœ…', 'åˆ†æ': 'ğŸ”',
            
            # æ¡†æ¶å’Œè¯­è¨€
            'Vue': 'ğŸ’š', 'React': 'âš›ï¸', 'Angular': 'ğŸ…°ï¸', 'Node': 'ğŸ“¦',
            'Python': 'ğŸ', 'Java': 'â˜•', 'JavaScript': 'ğŸ“œ', 'TypeScript': 'ğŸ“˜',
            'Go': 'ğŸ¹', 'Rust': 'ğŸ¦€', 'C++': 'âš™ï¸', 'PHP': 'ğŸ˜',
            
            # æ•°æ®ç›¸å…³
            'æ•°æ®': 'ğŸ“Š', 'ç»Ÿè®¡': 'ğŸ“ˆ', 'åˆ†æ': 'ğŸ“‰', 'å¯è§†åŒ–': 'ğŸ“Š',
            'ç®—æ³•': 'ğŸ§®', 'æ¨¡å‹': 'ğŸ§ ', 'å­¦ä¹ ': 'ğŸ“š', 'è®­ç»ƒ': 'ğŸ‹ï¸'
        }
        
        # ä¸ºæ ‡é¢˜æ·»åŠ è¡¨æƒ…
        def add_title_emoji(match):
            title = match.group(2)
            level = len(match.group(1))
            
            # æŸ¥æ‰¾æ ‡é¢˜ä¸­æ˜¯å¦åŒ…å«å…³é”®è¯
            emoji = None
            for keyword, e in title_emoji_map.items():
                if keyword in title:
                    emoji = e
                    break
            
            if emoji:
                return f"{'#' * level} {emoji} {title}"
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…çš„å…³é”®è¯ï¼Œæ ¹æ®æ ‡é¢˜çº§åˆ«æ·»åŠ é»˜è®¤è¡¨æƒ…
            if level == 1:
                return f"# ğŸ“‘ {title}"  # ä¸»æ ‡é¢˜
            elif level == 2:
                return f"## ğŸ“Œ {title}"  # äºŒçº§æ ‡é¢˜
            elif level == 3:
                return f"### ğŸ“ {title}"  # ä¸‰çº§æ ‡é¢˜
            
            return match.group(0)
        
        # å¤„ç†æ ‡å‡†æ ¼å¼çš„æ ‡é¢˜
        content = re.sub(r'^(#{1,6})\s+(.+)$', add_title_emoji, content, flags=re.MULTILINE)
        
        # å¤„ç†å¯èƒ½æ²¡æœ‰ç©ºæ ¼çš„æ ‡é¢˜æ ¼å¼
        content = re.sub(r'^(#{1,6})([^#\s].+)$', r'\1 \2', content, flags=re.MULTILINE)
        # å†æ¬¡åº”ç”¨è¡¨æƒ…ç¬¦å·
        content = re.sub(r'^(#{1,6})\s+(.+)$', add_title_emoji, content, flags=re.MULTILINE)
        
        return content
    
    def _markdown_to_rich_text_v2(self, markdown_content):
        """ä¼˜åŒ–ç‰ˆMarkdownåˆ°å¯Œæ–‡æœ¬è½¬æ¢ v2.0"""
        if not markdown_content:
            return ""
        
        try:
            # å…ˆè½¬æ¢ä¸ºHTML
            html_content = self.markdown_converter.convert(markdown_content)
            
            # ä½¿ç”¨æ”¹è¿›çš„HTMLåˆ°æ–‡æœ¬è½¬æ¢
            rich_text = self._html_to_formatted_text_v2(html_content)
            
            return rich_text
            
        except Exception as e:
            print(f"âš ï¸ å¯Œæ–‡æœ¬è½¬æ¢å¤±è´¥: {e}")
            return self._markdown_to_plain_text_v2(markdown_content)
    
    def _html_to_formatted_text_v2(self, html_content):
        """æ”¹è¿›ç‰ˆHTMLåˆ°æ ¼å¼åŒ–æ–‡æœ¬è½¬æ¢ - é€‚é…ä»Šæ—¥å¤´æ¡ç¼–è¾‘å™¨"""
        if not html_content:
            return ""
        
        # ä½¿ç”¨BeautifulSoupè§£æHTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        def process_element(element, depth=0):
            if isinstance(element, NavigableString):
                text = str(element).strip()
                return text if text else ""
            
            if not hasattr(element, 'name'):
                return ""
            
            tag_name = element.name.lower()
            
            # è·å–æ‰€æœ‰å­å…ƒç´ çš„æ–‡æœ¬
            children_texts = []
            for child in element.children:
                child_text = process_element(child, depth + 1)
                if child_text:
                    children_texts.append(child_text)
            
            content = ' '.join(children_texts) if children_texts else element.get_text().strip()
            
            # æ ¹æ®æ ‡ç­¾ç±»å‹æ ¼å¼åŒ–
            if tag_name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                level = int(tag_name[1])
                if content:
                    prefix = '#' * level + ' '
                    return f"\n\n{prefix}{content}\n\n"
                    
            elif tag_name == 'p':
                if content:
                    return f"\n\n{content}\n\n"
                    
            elif tag_name in ['strong', 'b']:
                return content  # ä¾èµ–ç¼–è¾‘å™¨çš„åŠ ç²—åŠŸèƒ½
                
            elif tag_name in ['em', 'i']:
                return content  # ä¾èµ–ç¼–è¾‘å™¨çš„æ–œä½“åŠŸèƒ½
                
            elif tag_name == 'code':
                if content:
                    return content  # ä¾èµ–ç¼–è¾‘å™¨çš„ä»£ç æ ¼å¼åŠŸèƒ½
            
            elif tag_name == 'pre':
                if content:
                    # æ£€æµ‹ä»£ç è¯­è¨€
                    code_elem = element.find('code')
                    language = ""
                    if code_elem and code_elem.get('class'):
                        classes = ' '.join(code_elem.get('class', []))
                        lang_match = re.search(r'language-(\w+)', classes)
                        if lang_match:
                            language = lang_match.group(1)
                    
                    return f"\n\n{content}\n\n"  # ä¾èµ–ç¼–è¾‘å™¨çš„ä»£ç å—åŠŸèƒ½
                        
            elif tag_name in ['ul', 'ol']:
                if children_texts:
                    list_content = '\n'.join(children_texts)
                    return f"\n\n{list_content}\n\n"
                    
            elif tag_name == 'li':
                parent = element.parent
                if parent and parent.name == 'ol':
                    # æœ‰åºåˆ—è¡¨
                    index = 1
                    for sibling in element.previous_siblings:
                        if sibling.name == 'li':
                            index += 1
                    return f"{index}. {content}"
                else:
                    # æ— åºåˆ—è¡¨
                    return f"â€¢ {content}"
            
            elif tag_name == 'blockquote':
                if content:
                    return f"\n\n{content}\n\n"  # ä¾èµ–ç¼–è¾‘å™¨çš„å¼•ç”¨åŠŸèƒ½
                    
            elif tag_name == 'a':
                href = element.get('href', '')
                if content and href:
                    return content  # ä¾èµ–ç¼–è¾‘å™¨çš„é“¾æ¥åŠŸèƒ½
                else:
                    return content
            
            elif tag_name == 'img':
                alt = element.get('alt', 'å›¾ç‰‡')
                src = element.get('src', '')
                if src:
                    return f"\n\n[å›¾ç‰‡]\n\n"  # å›¾ç‰‡éœ€è¦æ‰‹åŠ¨ä¸Šä¼ 
            
            elif tag_name in ['br']:
                return "\n"
            
            elif tag_name in ['hr']:
                return "\n\n---\n\n"
            
            elif tag_name in ['div', 'section', 'article']:
                if children_texts:
                    return ' '.join(children_texts)
                else:
                    return content
            
            else:
                return content
        
        # å¤„ç†æ•´ä¸ªæ–‡æ¡£
        result = process_element(soup)
        
        # åå¤„ç†ï¼šæ¸…ç†æ ¼å¼
        if result:
            # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
            result = re.sub(r'\n{3,}', '\n\n', result)
            # æ¸…ç†å¤šä½™çš„ç©ºæ ¼
            result = re.sub(r'[ \t]+', ' ', result)
            # ç¡®ä¿æ®µè½é—´æœ‰ç©ºè¡Œ
            result = re.sub(r'([^\n])\n([^\n])', r'\1\n\n\2', result)
            result = result.strip()
        
        return result
    
    def _markdown_to_plain_text_v2(self, markdown_content):
        """æ”¹è¿›ç‰ˆMarkdownåˆ°çº¯æ–‡æœ¬è½¬æ¢ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        if not markdown_content:
            return ""
        
        text = markdown_content
        
        # å¤„ç†æ ‡é¢˜ï¼ˆä¿æŒå±‚çº§ä½†ç¾åŒ–æ ¼å¼ï¼‰
        text = re.sub(r'^#{1}\s+(.+)$', r'\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\1\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{2}\s+(.+)$', r'\n\nâ–¶ \1\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n', text, flags=re.MULTILINE)
        text = re.sub(r'^#{3,6}\s+(.+)$', r'\n\nâ— \1\n\n', text, flags=re.MULTILINE)
        
        # å¤„ç†ä»£ç å—
        text = re.sub(r'```(\w*)\n(.*?)\n```', r'\n\nğŸ’» **ä»£ç ç¤ºä¾‹ï¼š**\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n\2\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n', text, flags=re.DOTALL)
        
        # å¤„ç†å†…è”ä»£ç 
        text = re.sub(r'`([^`]+)`', r' `\1` ', text)
        
        # å¤„ç†ç²—ä½“å’Œæ–œä½“
        text = re.sub(r'\*\*([^*]+)\*\*', r'**\1**', text)
        text = re.sub(r'\*([^*]+)\*', r'*\1*', text)
        
        # å¤„ç†å¼•ç”¨
        text = re.sub(r'^>\s*(.+)$', r'â”ƒ \1', text, flags=re.MULTILINE)
        
        # å¤„ç†åˆ—è¡¨
        text = re.sub(r'^[-*+]\s+(.+)$', r'â€¢ \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\d+\.\s+(.+)$', r'â€¢ \1', text, flags=re.MULTILINE)
        
        # å¤„ç†é“¾æ¥
        text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'[\1](\2)', text)
        
        # å¤„ç†åˆ†éš”çº¿
        text = re.sub(r'^---+$', 'â”€' * 50, text, flags=re.MULTILINE)
        
        # æœ€ç»ˆæ¸…ç†
        return self._postprocess_text_v2(text)
    
    def save_article_file(self, title, content, tags, url):
        """ä¿å­˜æ–‡ç« åˆ°æ–‡ä»¶"""
        # åˆ›å»ºæ–‡ä»¶åï¼ˆä½¿ç”¨URLçš„hashé¿å…é‡å¤ï¼‰
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        safe_title = re.sub(r'[^\w\s-]', '', title).strip()
        safe_title = re.sub(r'[-\s]+', '-', safe_title)[:50]
        
        filename = f"forwarded-enhanced-{safe_title}-{url_hash}.md"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        today = datetime.now().strftime('%Y-%m-%d')
        target_dir = f"articles/{today}"
        os.makedirs(target_dir, exist_ok=True)
        
        file_path = os.path.join(target_dir, filename)
        
        # å¢å¼ºå†…å®¹æ ¼å¼ï¼ˆä¿å­˜Markdownç‰ˆæœ¬ï¼‰
        enhanced_content = self._enhance_content_format(title, content, url, use_rich_text=False)
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(enhanced_content)
        
        print(f"ğŸ’¾ æ–‡ç« å·²ä¿å­˜: {file_path}")
        return file_path
    
    async def forward_to_toutiao(self, title, content, tags, url, account_file):
        """è½¬å‘æ–‡ç« åˆ°ä»Šæ—¥å¤´æ¡"""
        print("ğŸš€ å¼€å§‹å‘å¸ƒåˆ°ä»Šæ—¥å¤´æ¡...")
        
        try:
            # å¢å¼ºå†…å®¹æ ¼å¼å¹¶è½¬æ¢ä¸ºå¯Œæ–‡æœ¬
            enhanced_content = self._enhance_content_format(title, content, url, use_rich_text=True)
            
            # åˆ›å»ºæ–‡ç« å‘å¸ƒå¯¹è±¡
            article = TouTiaoArticle(
                title=title,
                content=enhanced_content,
                tags=tags,
                publish_date=0,  # ç«‹å³å‘å¸ƒ
                account_file=account_file,
                cover_path=None  # è‡ªåŠ¨ç”Ÿæˆå°é¢
            )
            
            # å‘å¸ƒæ–‡ç« 
            async with async_playwright() as playwright:
                await article.upload(playwright)
            
            print(f"âœ… æ–‡ç« å‘å¸ƒæˆåŠŸ: {title}")
            return True
            
        except Exception as e:
            print(f"âŒ æ–‡ç« å‘å¸ƒå¤±è´¥: {e}")
            return False

class AIContentEnhancer:
    """AIå†…å®¹å¢å¼ºå™¨ - ä½¿ç”¨OpenAIä¼˜åŒ–æ–‡ç« æ’ç‰ˆå’Œå†…å®¹"""
    
    def __init__(self, api_key: Optional[str] = None):
        """åˆå§‹åŒ–AIå†…å®¹å¢å¼ºå™¨"""
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        print(f"API Key: {self.api_key}")
        if self.api_key:
            openai.api_key = self.api_key
        self.model = "gpt-3.5-turbo-16k"
    
    def enhance_content(self, title: str, content: str, tags: List[str]) -> Dict[str, str]:
        """ä½¿ç”¨AIå¢å¼ºå†…å®¹è´¨é‡"""
        if not self.api_key:
            print("âš ï¸ æœªé…ç½®OpenAI API Keyï¼Œè·³è¿‡AIå¢å¼º")
            return {"title": title, "content": content}
            
        try:
            print("ğŸ¤– æ­£åœ¨ä½¿ç”¨AIä¼˜åŒ–å†…å®¹...")
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡ç« ç¼–è¾‘ï¼Œè¯·å¸®æˆ‘ä¼˜åŒ–ä»¥ä¸‹æ–‡ç« çš„æ’ç‰ˆå’Œå†…å®¹ï¼Œè¦æ±‚ï¼š
            1. ä¿æŒåŸæ–‡çš„æ ¸å¿ƒå†…å®¹å’ŒæŠ€æœ¯å‡†ç¡®æ€§
            2. ä¼˜åŒ–æ ‡é¢˜ä½¿å…¶æ›´å¸å¼•äººï¼Œä½†ä¸è¦è¿‡åˆ†å¤¸å¼ 
            3. æ”¹è¿›æ–‡ç« ç»“æ„ï¼Œä½¿å…¶æ›´æœ‰é€»è¾‘æ€§
            4. ä¼˜åŒ–æ®µè½åˆ†å¸ƒï¼Œä½¿æ–‡ç« æ›´æ˜“è¯»
            5. é€‚å½“æ·»åŠ å°æ ‡é¢˜å’Œåˆ†éš”ç¬¦
            6. åœ¨å…³é”®ç‚¹æ·»åŠ åˆé€‚çš„emoji
            7. ç¡®ä¿ä»£ç å—æ ¼å¼æ­£ç¡®
            8. é€‚å½“æ·»åŠ è¦ç‚¹ç¬¦å·
            9. ä¿æŒä¸“ä¸šæ€§å’Œå¯è¯»æ€§çš„å¹³è¡¡
            10. è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯Markdown
            11. ä¸è¦åœ¨å†…å®¹å¼€å¤´æ·»åŠ æ–‡ç« æ ‡é¢˜ï¼Œæ ‡é¢˜å°†å•ç‹¬å¤„ç†

            åŸæ ‡é¢˜: {title}
            æ ‡ç­¾: {', '.join(tags)}
            
            åŸæ–‡å†…å®¹:
            {content}
            """
            
            # è°ƒç”¨OpenAI API
            response = openai.ChatCompletion.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡ç« ç¼–è¾‘ï¼Œç²¾é€šæŠ€æœ¯å†™ä½œå’Œæ’ç‰ˆä¼˜åŒ–ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=4000
            )
            
            # è§£æå“åº”
            enhanced_content = response.choices[0].message.content.strip()
            
            # æå–ä¼˜åŒ–åçš„æ ‡é¢˜ï¼ˆå¦‚æœAIç”Ÿæˆäº†æ–°æ ‡é¢˜ï¼‰
            new_title = title
            if enhanced_content.startswith('# '):
                # æå–AIç”Ÿæˆçš„æ ‡é¢˜
                first_line = enhanced_content.split('\n')[0]
                potential_title = first_line.lstrip('# ').strip()
                if potential_title:  # å¦‚æœæœ‰å†…å®¹ï¼Œä½¿ç”¨å®ƒä½œä¸ºæ–°æ ‡é¢˜
                    new_title = potential_title
                # æ— è®ºå¦‚ä½•ï¼Œä»å†…å®¹ä¸­ç§»é™¤æ ‡é¢˜è¡Œ
                enhanced_content = '\n'.join(enhanced_content.split('\n')[1:]).strip()
            
            # å†æ¬¡æ£€æŸ¥æ˜¯å¦æœ‰æ ‡é¢˜æ ¼å¼çš„è¡Œï¼ˆæœ‰æ—¶AIä¼šæ·»åŠ å¤šä¸ªæ ‡é¢˜ï¼‰
            if enhanced_content.startswith('# '):
                enhanced_content = re.sub(r'^#\s+.*?\n', '', enhanced_content, count=1, flags=re.MULTILINE)
            
            print("âœ¨ AIå†…å®¹ä¼˜åŒ–å®Œæˆ")
            return {
                "title": new_title,
                "content": enhanced_content
            }
            
        except Exception as e:
            print(f"âš ï¸ AIå¢å¼ºè¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}")
            return {"title": title, "content": content}
    
    def generate_seo_tags(self, title: str, content: str) -> List[str]:
        """ä½¿ç”¨AIç”ŸæˆSEOä¼˜åŒ–çš„æ ‡ç­¾"""
        if not self.api_key:
            return []
            
        try:
            print("ğŸ·ï¸ æ­£åœ¨ä½¿ç”¨AIç”Ÿæˆä¼˜åŒ–æ ‡ç­¾...")
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""ä½œä¸ºSEOä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹æŠ€æœ¯æ–‡ç« ç”Ÿæˆ3-5ä¸ªæœ€ç›¸å…³çš„æ ‡ç­¾ï¼Œè¦æ±‚ï¼š
            1. æ ‡ç­¾è¦å‡†ç¡®åæ˜ æ–‡ç« æ ¸å¿ƒä¸»é¢˜
            2. åŒ…å«æŠ€æœ¯é¢†åŸŸå’Œå…·ä½“æŠ€æœ¯ç‚¹
            3. è€ƒè™‘æœç´¢çƒ­åº¦å’Œç›¸å…³æ€§
            4. ä¸è¦ä½¿ç”¨è¿‡äºå®½æ³›çš„æ ‡ç­¾
            5. è¾“å‡ºæ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªæ ‡ç­¾ï¼Œä¸è¦åŒ…å«#å·

            æ–‡ç« æ ‡é¢˜: {title}
            
            æ–‡ç« å†…å®¹:
            {content[:2000]}  # åªä½¿ç”¨å‰2000ä¸ªå­—ç¬¦
            """
            
            # è°ƒç”¨OpenAI API
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªSEOä¸“å®¶ï¼Œç²¾é€šæŠ€æœ¯æ–‡ç« æ ‡ç­¾ä¼˜åŒ–ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=100
            )
            
            # è§£æå“åº”
            tags = [tag.strip() for tag in response.choices[0].message.content.strip().split('\n')]
            print(f"âœ¨ AIæ ‡ç­¾ç”Ÿæˆå®Œæˆ: {tags}")
            return tags
            
        except Exception as e:
            print(f"âš ï¸ AIæ ‡ç­¾ç”Ÿæˆå‡ºç°é”™è¯¯: {str(e)}")
            return []

async def forward_article_from_url(url, account_file="cookiesFile/toutiao_cookie.json", save_file=True):
    """ä»URLè½¬å‘æ–‡ç« åˆ°ä»Šæ—¥å¤´æ¡"""
    try:
        logger.info(f"ğŸ” æ£€æŸ¥ç™»å½•çŠ¶æ€... account_file={account_file}")
        if not await toutiao_setup(account_file):
            logger.error("âŒ ç™»å½•çŠ¶æ€å¤±æ•ˆï¼Œè¯·é‡æ–°ç™»å½•")
            logger.error("æç¤º: è¿è¡Œ python examples/login_toutiao.py é‡æ–°ç™»å½•")
            return None
        logger.info("âœ… ç™»å½•çŠ¶æ€æ­£å¸¸")
        
        forwarder = EnhancedArticleForwarder()
        logger.info("å‡†å¤‡è·å–æ–‡ç« å†…å®¹")
        try:
            title, content, tags = await forwarder.fetch_article(url)
        except Exception as e:
            logger.error(f"fetch_article å¼‚å¸¸: {e}", exc_info=True)
        logger.info("fetch_article æ‰§è¡Œå®Œæ¯•")
        logger.info(f"è·å–ç»“æœ: title={title}, content={content}, tags={tags}")
        
        if not title or not content:
            logger.error("âŒ æ–‡ç« è·å–å¤±è´¥")
            return None
        
        if save_file:
            file_path = forwarder.save_article_file(title, content, tags, url)
            if file_path:
                logger.info(f"ğŸ’¾ æ–‡ç« å·²ä¿å­˜: {file_path}")
        
        return {
            'title': title,
            'content': content,
            'tags': tags
        }
        
    except Exception as e:
        logger.error(f"âŒ è·å–æ–‡ç« å¤±è´¥: {str(e)}", exc_info=True)
        return None

async def publish_article_to_toutiao(title, content, tags, url, account_file="cookiesFile/toutiao_cookie.json"):
    try:
        logger.info(f"âš ï¸ å³å°†è½¬å‘æ–‡ç« åˆ°ä»Šæ—¥å¤´æ¡: æ ‡é¢˜={title}, æ ‡ç­¾={tags}, æ¥æº={url}")
        logger.info(f"ğŸ¨ æ’ç‰ˆ: å·²å¯ç”¨å¢å¼ºæ’ç‰ˆæ¨¡å¼, ğŸ”„ æ ¼å¼: Markdown â†’ å¯Œæ–‡æœ¬æ ¼å¼")
        logger.info(f"ğŸ”’ éªŒè¯ç : å¦‚é‡éªŒè¯ç å°†ç­‰å¾…ç”¨æˆ·è¾“å…¥")
        forwarder = EnhancedArticleForwarder()
        logger.info("ğŸš€ å¼€å§‹å‘å¸ƒåˆ°ä»Šæ—¥å¤´æ¡... å‡†å¤‡è°ƒç”¨forward_to_toutiao")
        logger.info("è°ƒç”¨forward_to_toutiaoå‰")
        success = await forwarder.forward_to_toutiao(title, content, tags, url, account_file)
        logger.info(f"è°ƒç”¨forward_to_toutiaoåï¼Œç»“æœ: {success}")
        if success:
            logger.info("ğŸ‰ æ–‡ç« è½¬å‘å®Œæˆï¼è¯·ç™»å½•ä»Šæ—¥å¤´æ¡æŸ¥çœ‹å‘å¸ƒç»“æœ")
        else:
            logger.error("âŒ æ–‡ç« è½¬å‘å¤±è´¥")
        return success
    except Exception as e:
        logger.error(f"âŒ å‘å¸ƒæ–‡ç« åˆ°å¤´æ¡å¼‚å¸¸: {str(e)}", exc_info=True)
        return False

async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä»URLè½¬å‘æ–‡ç« åˆ°ä»Šæ—¥å¤´æ¡')
    parser.add_argument('url', help='è¦è½¬å‘çš„æ–‡ç« URL')
    parser.add_argument('--no-save', action='store_false', dest='save_file',
                      help='ä¸ä¿å­˜æ–‡ç« åˆ°æœ¬åœ°')
    parser.add_argument('--preview', action='store_true',
                      help='é¢„è§ˆæ¨¡å¼ï¼Œåªæ˜¾ç¤ºæ–‡ç« å†…å®¹ä¸å‘å¸ƒ')
    parser.add_argument('--no-ai', action='store_false', dest='use_ai',
                      help='ä¸ä½¿ç”¨AIå¢å¼ºåŠŸèƒ½')
    args = parser.parse_args()

    # æ˜¾ç¤ºå‚æ•°ä¿¡æ¯
    print(f"ğŸ”— ç›®æ ‡é“¾æ¥: {args.url}")
    print(f"ğŸ”‘ è´¦å·æ–‡ä»¶: cookiesFile/toutiao_cookie.json")
    print(f"ğŸ’¾ ä¿å­˜æ–‡ä»¶: {'æ˜¯' if args.save_file else 'å¦'}")
    print(f"ğŸ‘€ é¢„è§ˆæ¨¡å¼: {'æ˜¯' if args.preview else 'å¦'}")
    print(f"ğŸ¤– AIå¢å¼º: {'æ˜¯' if args.use_ai else 'å¦'}")
    print(f"âœ¨ ç‰ˆæœ¬: WechatSyncé£æ ¼æ’ç‰ˆ v3.0 (å¢å¼ºä»£ç å—ã€æ ‡é¢˜ç¾åŒ–)")
    print("ğŸ”— å¢å¼ºç‰ˆæ–‡ç« é“¾æ¥è½¬å‘å·¥å…· v2.1")
    print("=" * 60)

    try:
        # è·å–æ–‡ç« å†…å®¹
        article = await forward_article_from_url(
            args.url,
            save_file=args.save_file
        )
        
        if not article:
            print("âŒ æ–‡ç« è·å–å¤±è´¥")
            return

        article_title = article.get('title', '')
        article_content = article.get('content', '')
        article_tags = article.get('tags', [])
        
        # ä½¿ç”¨AIå¢å¼ºå†…å®¹
        if args.use_ai:
            try:
                from conf import OPENAI_API_KEY
                ai_enhancer = AIContentEnhancer(api_key=OPENAI_API_KEY)
                
                # AIå¢å¼ºå†…å®¹
                enhanced = ai_enhancer.enhance_content(
                    title=article_title,
                    content=article_content,
                    tags=article_tags
                )
                article_title = enhanced["title"]
                article_content = enhanced["content"]
                
                # ç”Ÿæˆä¼˜åŒ–çš„æ ‡ç­¾
                ai_tags = ai_enhancer.generate_seo_tags(article_title, article_content)
                if ai_tags:
                    article_tags.extend(ai_tags)
                    article_tags = list(set(article_tags))  # å»é‡
            except ImportError:
                print("âš ï¸ æœªæ‰¾åˆ°OpenAI APIé…ç½®ï¼Œè·³è¿‡AIå¢å¼º")
            except Exception as e:
                print(f"âš ï¸ AIå¢å¼ºè¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}")

        if args.preview:
            print("\nğŸ“ é¢„è§ˆæ–‡ç« å†…å®¹:")
            print("=" * 60)
            print(f"æ ‡é¢˜: {article_title}")
            print(f"æ ‡ç­¾: {article_tags}")
            print("-" * 60)
            print(article_content)
            print("=" * 60)
            return

        # å‘å¸ƒæ–‡ç« 
        await publish_article_to_toutiao(
            title=article_title,
            content=article_content,
            tags=article_tags,
            url=args.url
        )

    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 